{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI University","text":"<p>Welcome to the AI University Curriculum. Use the left menu to pick a week.</p>"},{"location":"cheat-sheet/","title":"Cheat Sheets","text":"<p>Quick Reminder Cheat Sheets</p>"},{"location":"cheat-sheet/#1-everyday-workflow-edit-preview-commit-deploy","title":"1. Everyday Workflow (Edit \u2192 Preview \u2192 Commit \u2192 Deploy)","text":"<p>Local preview</p> <p><pre><code>python -m mkdocs serve\n</code></pre> Open: http://127.0.0.1:8000/ (Leave terminal running; Ctrl+C stops it.)</p> <p>Commit &amp; push <pre><code>git add docs/...\ngit commit -m \"Your message\"\ngit push origin main\n</code></pre> Publish to GitHub Pages <pre><code>python -m mkdocs gh-deploy\n</code></pre></p>"},{"location":"cheat-sheet/#2-common-git-commands","title":"2. Common Git Commands","text":"<pre><code>git status                 # see what changed\ngit add &lt;file&gt;             # stage a file\ngit add .                  # stage everything\ngit commit -m \"message\"    # commit staged changes\ngit push origin main       # push to GitHub\ngit pull origin main       # pull latest from GitHub\n</code></pre> <p>Undo a staged file: <pre><code>git restore --staged &lt;file&gt;\n</code></pre></p>"},{"location":"cheat-sheet/#3-mkdocs-basics","title":"3. MkDocs Basics","text":"<p>Edit pages in <code>docs/</code> Navigation lives in <code>mkdocs.yml</code> under <code>nav:</code></p> <p>Rebuild local site <pre><code>python -m mkdocs serve\n</code></pre></p> <p>Deploy to GitHub Pages <pre><code>python -m mkdocs gh-deploy\n</code></pre></p>"},{"location":"cheat-sheet/#add-a-new-page","title":"Add a new page","text":"<ol> <li>Create <code>docs/new-page.md</code></li> <li>Add to <code>mkdocs.yml</code>: <pre><code>nav:\n  - Home: index.md\n  - Week 1: week-1.md\n  - Week 2: week-2.md\n  - Cheat Sheets: cheat-sheet.md\n  - New Page: new-page.md\n  ```\n\n## 4. VS Code Tips\nToggle terminal: **Ctrl + `**\nCommand Palette: **Ctrl + Shift + P**\nFind/Replace regex: **Ctrl + H**, click `.*`\nReload the window (fix UI glitches): **Developer: Reload Window**\n\n  ## 5. Troubleshooting\n```bash\npython -m mkdocs serve\n</code></pre></li> </ol> <p>Use <code>http://127.0.0.1:8000/</code> (colon, not dot).</p>"},{"location":"cheat-sheet/#github-pages-not-updated","title":"GitHub Pages not updated","text":"<pre><code>python -m mkdocs gh-deploy\n</code></pre> <p>Wait ~30 seconds and refresh the live site.</p>"},{"location":"cheat-sheet/#site-shows-up-in-git-changes","title":"<code>site/</code> shows up in Git changes","text":"<p>Ensure <code>.gitignore</code> contains <code>site/</code>.</p> <p>If it's already tracked: <pre><code>git rm -r --cached site\ngit commit -m \"Remove generated site\"\ngit push origin main\n</code></pre></p>"},{"location":"roadmap/","title":"Curriculum Roadmap","text":"<p>A high\u2011level view of all 24 weeks. Click into each Week page for full details.</p>"},{"location":"roadmap/#term-1-aiu-101-introduction-to-ai-ml-weeks-16","title":"Term 1 \u2014 AIU\u202f101: Introduction to AI &amp; ML  (Weeks 1\u20136)","text":"Week 1 \u2013 History of AI &amp; Math Foundations <p>Module Title: History of AI &amp; Math Foundations Focus: AI milestones, core definitions (AI/ML/Data Science), probability (mean/variance), linear algebra (vectors/matrices), tool setup. Outputs: Working Python/Jupyter env, 10 math/probability exercises. Link: Week\u00a01 details</p> Week 2 \u2013 Supervised Learning: Regression &amp; Classification <ul> <li>Linear vs. logistic regression (MSE, cross\u2011entropy)  </li> <li>Metrics: R\u00b2, accuracy, precision/recall, F1  </li> <li>Overfitting vs. underfitting Tools: scikit\u2011learn, matplotlib Deliverable: Train &amp; evaluate a regression + classification model</li> </ul> Week 3 \u2013 Unsupervised Learning: Clustering &amp; PCA <ul> <li>k\u2011means, elbow method, hierarchical clustering  </li> <li>PCA for dimensionality reduction, variance explained  </li> <li>Customer segmentation case study Tools: scikit\u2011learn, seaborn Deliverable: Segment a dataset &amp; visualize clusters</li> </ul> Week 4 \u2013 Neural Network Basics <ul> <li>Perceptron, activations, MLP architecture  </li> <li>Backpropagation &amp; gradient descent  </li> <li>Regularization: dropout, weight decay Tools: TensorFlow/Keras or PyTorch Deliverable: Build a simple MLP on a tabular dataset</li> </ul> Week 5 \u2013 Ethics, Bias &amp; Responsible AI <ul> <li>Bias sources, fairness metrics (demographic parity, equal opportunity)  </li> <li>Privacy (GDPR), governance frameworks Tools: pandas for subgroup analysis Deliverable: Bias audit on a sample dataset</li> </ul> Week 6 \u2013 Mini Project: Regression Pipeline <ul> <li>Data loading \u2192 cleaning \u2192 splitting  </li> <li>Hyperparameter tuning &amp; reporting Tools: scikit\u2011learn Pipelines, matplotlib Deliverable: End\u2011to\u2011end regression report</li> </ul>"},{"location":"roadmap/#term-2-aiu-201-handson-with-python-ai-frameworks-weeks-712","title":"Term 2 \u2014 AIU\u202f201: Hands\u2011On with Python AI Frameworks  (Weeks 7\u201312)","text":"Week 7 \u2013 Environment Setup &amp; Version Control <ul> <li>Conda vs. venv, install TF/PyTorch/scikit\u2011learn  </li> <li>Jupyter best practices, Git basics Tools: Anaconda, Git/GitHub Deliverable: Reproducible env + first committed notebook</li> </ul> Week 8 \u2013 Data Wrangling &amp; Pipelines <ul> <li>pandas filtering, groupby, merge  </li> <li>Missing data/outliers, feature scaling  </li> <li>sklearn <code>Pipeline</code> Tools: pandas, scikit\u2011learn Deliverable: Reusable data-cleaning pipeline</li> </ul> Week 9 \u2013 Model Building in scikit\u2011learn <ul> <li>Estimator overview, GridSearchCV  </li> <li>Model evaluation pipeline, joblib export Tools: scikit\u2011learn, joblib Deliverable: Tuned model saved &amp; reloaded</li> </ul> Week 10 \u2013 Deep Learning with TensorFlow/Keras <ul> <li>Sequential vs. Functional API  </li> <li>Dense/Conv/LSTM layers, callbacks (EarlyStopping)  </li> <li>TensorBoard monitoring Tools: TensorFlow/Keras, TensorBoard Deliverable: Trained DL model with tracked metrics</li> </ul> Week 11 \u2013 Custom Architectures in PyTorch <ul> <li><code>nn.Module</code>, custom layers  </li> <li><code>Dataset</code>/<code>DataLoader</code>, training loop (forward/backward/step)  </li> <li>Saving/loading <code>state_dict</code> Tools: PyTorch Deliverable: Custom PyTorch model &amp; clean training script</li> </ul> Week 12 \u2013 Deploying &amp; Serving Models <ul> <li>Export formats (SavedModel, TorchScript)  </li> <li>Flask/FastAPI basics, Docker containerization  </li> <li>REST endpoint design Tools: Flask/FastAPI, Docker Deliverable: Local API serving a model</li> </ul>"},{"location":"roadmap/#term-3-aiu-301-ai-for-business-personal-productivity-weeks-1318","title":"Term 3 \u2014 AIU\u202f301: AI for Business &amp; Personal Productivity  (Weeks 13\u201318)","text":"Week 13 \u2013 Marketing Automation &amp; Predictive Lead Scoring <ul> <li>Feature engineering (opens, clicks, demographics)  </li> <li>Logistic vs. tree models, lift charts, ROI  </li> <li>CRM integration Tools: OpenAI API, LangChain, Streamlit Deliverable: Lead scoring prototype &amp; dashboard</li> </ul> Week 14 \u2013 Inventory Forecasting <ul> <li>SARIMA vs. Prophet vs. LSTM  </li> <li>STL decomposition, error metrics (MAPE, MASE)  </li> <li>Auto\u2011reorder alerts Tools: Prophet, pandas, matplotlib Deliverable: Forecast report &amp; alert script</li> </ul> Week 15 \u2013 Quality of Earnings (QoE) with Anomaly Detection <ul> <li>QoE definition, IsolationForest, One\u2011Class SVM  </li> <li>Visualizing anomalies on financial time series Tools: scikit\u2011learn, Plotly Deliverable: Anomaly report for a sample financial dataset</li> </ul> Week 16 \u2013 Customer Training &amp; Chatbot Design <ul> <li>Instructional design for bots, intents/entities  </li> <li>OpenAI GPT integration, fallback flows, metrics Tools: Landbot/Chatfuel, OpenAI API Deliverable: Prototype customer\u2011support chatbot</li> </ul> Week 17 \u2013 Personal Productivity with AI <ul> <li>Smart schedulers, AI writing/summarization, auto\u2011notes  </li> <li>Ethics of personal data use Tools: Microsoft Copilot, Otter.ai Deliverable: Personal AI productivity stack configured</li> </ul> Week 18 \u2013 No\u2011Code AI Workflows <ul> <li>Zapier/Make triggers &amp; actions  </li> <li>Error handling, monitoring  </li> <li>API connections sans code Tools: Zapier, Make, Bubble Deliverable: Automated workflow for a repetitive business task</li> </ul>"},{"location":"roadmap/#term-4-aiu-401-capstone-advanced-ops-weeks-1924","title":"Term 4 \u2014 AIU\u202f401: Capstone &amp; Advanced Ops  (Weeks 19\u201324)","text":"Week 19 \u2013 Capstone Proposal &amp; Scoping <ul> <li>Project charter, scope, deliverables  </li> <li>Stakeholders &amp; success metrics  </li> <li>Data requirements &amp; milestones Tools: GitHub Projects, Trello/Gantt tool Deliverable: Approved capstone charter</li> </ul> Week 20 \u2013 Data Collection &amp; Pipelines <ul> <li>ETL vs. ELT, REST ingestion, batch jobs  </li> <li>Data quality checks (schema, null ratios)  </li> <li>Airflow basics Tools: Airflow, Python scripts Deliverable: Automated data pipeline draft</li> </ul> Week 21 \u2013 Model Development &amp; Iteration <ul> <li>Experiment tracking (MLflow), Optuna tuning  </li> <li>Dataset/model versioning, CV strategies Tools: MLflow, Optuna, sklearn/TF Deliverable: Logged experiments &amp; best model artifacts</li> </ul> Week 22 \u2013 Deployment Architecture &amp; Monitoring <ul> <li>Dockerizing services, Kubernetes basics  </li> <li>Monitoring (Prometheus/Grafana), logging best practices Tools: Docker, k3s/minikube, Prometheus/Grafana Deliverable: Containerized model with metrics dashboard</li> </ul> Week 23 \u2013 Testing, Evaluation &amp; ROI <ul> <li>Unit/integration tests for ML  </li> <li>A/B testing frameworks  </li> <li>Measuring AI ROI Tools: pytest, Streamlit/BI dashboards Deliverable: Test suite + ROI report</li> </ul> Week 24 \u2013 Final Presentation &amp; Ethics Wrap\u2011Up <ul> <li>Storytelling &amp; visualization of impact  </li> <li>Ethical reflection: bias, misuse  </li> <li>Lessons learned &amp; next steps Tools: PowerPoint/Google Slides, Plotly/Dash Deliverable: Final presentation &amp; ethics checklist</li> </ul>"},{"location":"week-1/","title":"History of AI &amp; Math Foundations","text":""},{"location":"week-1/#1-lesson-overview","title":"1. Lesson Overview","text":"<p>Learning Objectives</p> <p>By the end of this lesson, you will be able to:</p> <ul> <li>Describe three pivotal AI milestones and their lasting impact.</li> <li>Define Artificial Intelligence (AI), Machine Learning (ML), and Data Science with clear examples.</li> <li>Understand probability fundamentals\u2014random variables, expectation, variance\u2014and compute them by hand and in Python.</li> <li>Grasp key linear algebra concepts\u2014vectors, matrices, dot products, matrix multiplication\u2014and see how they underpin AI algorithms.</li> <li>Install and launch the required tools (Python, Jupyter Notebook, NumPy, pandas) and execute basic code.</li> </ul>"},{"location":"week-1/#2-core-definitions","title":"2. Core Definitions","text":"Term Definition &amp; Citation Example Artificial Intelligence (AI) \u201cThe science and engineering of making intelligent machines, especially intelligent computer programs.\u201d \u2014 John McCarthy, 1956 A chatbot that interprets questions and crafts human\u2011like responses. Machine Learning (ML) Algorithms that improve performance on tasks by learning from data rather than explicit programming. A regression model that learns to predict steel prices from historical sales. Data Science Interdisciplinary practice of using statistics, programming, and domain knowledge to extract insights from data. Cleaning and visualizing e\u2011commerce logs to uncover purchasing trends."},{"location":"week-1/#3-concept-sections","title":"3. Concept Sections","text":""},{"location":"week-1/#a-ai-milestones","title":"A. AI Milestones","text":"The Dartmouth Workshop (1956) <p>What happened: In summer 1956, John\u202fMcCarthy, Marvin\u202fMinsky, Nathaniel\u202fRochester, and Claude\u202fShannon met at Dartmouth College to ask: \u201cCan machines simulate human intelligence?\u201d They coined \u201cArtificial Intelligence\u201d and proposed studying how machines might \u201clearn from experience,\u201d \u201cmake abstractions,\u201d and \u201cuse language.\u201d</p> <p>Context &amp; significance: - Pre\u20111956, computers = number crunchers. Dartmouth reframed them as potential thinking machines. - Sparked optimism (and funding) that small teams could crack \u201cevery aspect of learning.\u201d</p> <p>First programs:     - Logic Theorist (1955) \u2013 Newell &amp; Simon proved logic theorems with a program.     - General Problem Solver (1957) \u2013 Early universal reasoning attempt.</p> <pre><code>!!! note \"Why this still matters\"\n    - Understanding the **hype \u2192 disappointment \u2192 AI winters** cycle helps you stay realistic about today\u2019s claims.  \n    - Symbolic reasoning/search ideas from this era live on in **knowledge graphs** and **constraint solvers**.\n</code></pre> Expert Systems Era (1970s\u20131980s) <p>Core idea: Encode expert knowledge as IF\u2013THEN rules.</p> <pre><code>IF symptom = fever AND symptom = rash\nTHEN suggest = measles\n</code></pre> <p>MYCIN (1972\u20131980): - ~600 rules to diagnose bacterial infections &amp; suggest antibiotics - Matched/surpassed human experts in blind tests</p> <p>Strengths vs. limits: - \u2705 Transparent logic (traceable to specific rules) - \u274c Hard to scale (thousands of hand\u2011written rules), weak with uncertainty</p> <p>Modern relevance</p> <ul> <li>Rule\u2011based logic still used in finance/healthcare compliance.  </li> <li>Today\u2019s hybrid systems: rules for regulation + ML models for scoring.</li> </ul> Deep Learning Boom (2010s\u2013Present) <p>Key breakthrough \u2013 AlexNet (2012): - 8\u2011layer CNN, cut ImageNet error rate in half (1.2M images, 1,000 classes) - Used ReLU, dropout, and GPU training.</p> <p>Why deep learning emerged: 1. Data: Huge labeled datasets (images, text, speech) 2. Compute: GPUs = fast parallel matrix ops 3. Algorithms: Batch norm, better backprop, new architectures</p> <p>Transformative apps: - Computer vision: self\u2011driving cars, medical imaging - NLP: translation, GPT\u2011style generation - Speech: voice assistants, real\u2011time translation</p> <p>Why this matters for you</p> <ul> <li>Modern frameworks (TensorFlow, PyTorch) are built around neural nets.  </li> <li>Explains why later terms focus on coding deep models &amp; leveraging pretrained architectures quickly.</li> </ul>"},{"location":"week-1/#c-probability-basics","title":"C. Probability Basics","text":"<p>Definition</p> <p>Probability Theory \u2013 \u201cThe mathematical framework for quantifying uncertainty and modeling random phenomena.\u201d</p>"},{"location":"week-1/#c1-gentle-introduction","title":"C1. Gentle Introduction","text":"1. What is Chance? <p>Analogy: Flipping a coin\u2014two outcomes, but you can\u2019t predict which. Key idea: Probability measures how likely something is (0 = impossible, 1 = certain). Example: A fair coin \u2192 P(heads) = 0.5.</p> 2. Simple Data &amp; Averages <p>Real example: Test scores: 80, 90, 70, 100, 60. Mean (average): <pre><code>(80 + 90 + 70 + 100 + 60) / 5 = 80\n</code></pre> Why it matters: The mean tells you what\u2019s \u201ctypical.\u201d</p> 3. Measuring Spread (Variance) <p>Analogy: Scores all near 80% \u2192 small spread; scores all over the place \u2192 big spread. Steps (using the score list above): 1. Subtract the mean (80): e.g. 60 \u2212 80 = \u221220 2. Square them: (\u221220)\u00b2 = 400 3. Average the squares \u2192 variance \u2248 280 4. Square root of variance \u2192 standard deviation \u2248 16.7 Why we care: Spread tells you how consistent or noisy data is\u2014critical for risk or quality control.</p>"},{"location":"week-1/#c2-formal-definitions-deep-dive","title":"C2. Formal Definitions &amp; Deep Dive","text":"1. Random Variables <p>A random variable (RV) assigns numbers to random outcomes.</p> <ul> <li>Discrete RV: countable values (die roll, number of returns)   Example: Fair die \u2192 <pre><code>X \u2208 {1,2,3,4,5,6},   P(X = k) = 1/6\n</code></pre></li> <li>Continuous RV: any value in a range (time between failures)   Example: Exponential distribution for time ( t \u2265 0 ): <pre><code>f(t) = \u03bb e^{\u2212\u03bb t}\n</code></pre></li> </ul> 2. Expectation (Mean) <p>Long\u2011run average outcome if you repeat forever.</p> <ul> <li>Discrete: <pre><code>E[X] = \u03a3 x_i \u00b7 P(X = x_i)\n</code></pre></li> <li>Continuous: <pre><code>E[X] = \u222b x f(x) dx\n</code></pre> Worked example (die): <pre><code>E[X] = (1+2+3+4+5+6) / 6 = 3.5\n</code></pre> Relevance: Loss functions (e.g., MSE) minimize expected error \u2192 expectation is baked into training.</li> </ul> 3. Variance &amp; Standard Deviation <p>Variance: average squared distance from the mean. <pre><code>Var(X) = E[(X \u2212 E[X])^2]\n</code></pre> Std. dev.: <pre><code>\u03c3 = \u221aVar(X)\n</code></pre> Die example: <pre><code>Var \u2248 2.92,  \u03c3 \u2248 1.71\n</code></pre> Why it matters: Tells you how uncertain predictions are, helps build confidence intervals, drives anomaly detection.</p> <p>Why Probability Matters in AI</p> <ul> <li>Model Training: Errors are expectations (means) over data.  </li> <li>Uncertainty: Variance underpins confidence, risk, anomaly flags.  </li> <li>Feature Engineering: Understanding distributions guides transformations (e.g., log scales for skewed data).</li> </ul>"},{"location":"week-1/#d-linear-algebra-basics","title":"D. Linear Algebra Basics","text":"<p>Definition</p> <p>Linear Algebra \u2013 \u201cThe branch of mathematics concerned with vectors, vector spaces, and linear transformations.\u201d</p>"},{"location":"week-1/#d1-gentle-introduction","title":"D1. Gentle Introduction","text":"1. Vectors as Lists <p>Analogy: A grocery list: <code>[2 bananas, 1 loaf bread, 500 g cheese]</code> Key idea: A vector is just a list of numbers representing features.</p> 2. Matrices as Tables <p>Analogy: A seating chart (rows = tables, columns = seats): <pre><code>       S1  S2  S3\n    T1  A   B   C\n    T2  D   E   F\n</code></pre> Key idea: A matrix stacks many vectors into rows or columns.</p> 3. Dot Product Intuition <p>Example (bill splitting): - You &amp; a friend order appetizers <code>[3, 2]</code> and drinks <code>[1, 2]</code>. - Prices: appetizers = \\$5, drinks = \\$2 \u2192 <pre><code>[3, 2] \u00b7 [5, 2] = 3\u00d75 + 2\u00d72 = 19\n</code></pre> Why it matters: Same math as a simple regression prediction (weights \u00d7 features).</p> 4. Real\u2011World Matrix Uses <ul> <li>Recipe scaling: Multiply ingredient matrix by 1.5 to go from 4 to 6 servings.  </li> <li>School timetable: Days \u00d7 hours grid to schedule classes.</li> </ul>"},{"location":"week-1/#d2-formal-definitions-deep-dive","title":"D2. Formal Definitions &amp; Deep Dive","text":"1. Vectors &amp; Their Interpretation <p>A vector x \u2208 \u211d\u207f is an ordered list of n numbers (features). Example: <pre><code>x = [age, monthly_spend, num_orders] = [45, 320.5, 12]\n</code></pre></p> 2. Matrices &amp; Batch Operations <p>A matrix X \u2208 \u211d^{m\u00d7n} stacks m row\u2011vectors of length n. Example (customer table): <pre><code>X = [\n  [45, 320.5, 12],\n  [23, 150.0,  5],\n  ...\n]\n</code></pre></p> 3. Dot Product &amp; Linear Transformations <p>Dot product: <pre><code>a \u00b7 b = \u03a3 (a_i * b_i)\n</code></pre> Use in AI: - Regression:  \u0177 = w \u00b7 x + b - Neural nets:  z = w \u00b7 x + b, then apply activation (e.g., ReLU)</p> 4. Matrix Multiplication <p><pre><code>C = A \u00d7 B,   C_{ij} = \u03a3_k A_{ik} B_{kj}\n</code></pre> Example: Combine/transform features or chain neural network layers.</p> Why Linear Algebra Matters in AI <ul> <li>Speed: GPUs/NumPy rely on vectorized (matrix) ops for efficiency.  </li> <li>Model Insight: Weights, activations, attention maps are matrices/vectors.  </li> <li>Dimensionality Reduction: PCA, SVD use eigenvectors/values to compress data.</li> </ul>"},{"location":"week-1/#4-tools-installation-setup","title":"4. Tools Installation &amp; Setup","text":"<p>You\u2019ll do this once, then reuse the environment all term.</p>"},{"location":"week-1/#a-install-python-anaconda-windows-mac","title":"A. Install Python &amp; Anaconda (Windows &amp; Mac)","text":"<p><pre><code># Visit this in your browser:\nhttps://www.anaconda.com/products/distribution\n</code></pre> 1. Download the Python 3.x installer for your OS. 2. Run the installer, accept defaults. 3. Open Anaconda Navigator (Start Menu on Windows / Applications on Mac).</p>"},{"location":"week-1/#b-launch-jupyter-notebook","title":"B. Launch Jupyter Notebook","text":"<ol> <li>In Anaconda Navigator, click Launch under Jupyter Notebook.  </li> <li>A browser window opens showing your files.  </li> <li>Click New \u2192 Python 3.  </li> <li>Rename it to Week1_AI_Math.ipynb.</li> </ol>"},{"location":"week-1/#c-install-import-numpy-pandas","title":"C. Install &amp; Import NumPy &amp; pandas","text":"<p>In a notebook cell, run: <pre><code>!conda install numpy pandas -y\n</code></pre> Then import: <pre><code>import numpy as np\nimport pandas as pd\n</code></pre></p> <p>Why these tools?</p> <ul> <li>Python/Jupyter: interactive coding &amp; math demos  </li> <li>NumPy: fast vectors/matrices (used everywhere in ML)  </li> <li>pandas: quick data tables, cleaning, summaries</li> </ul>"},{"location":"week-1/#5-step-by-step-exercises","title":"5. Step by Step Exercises","text":"Exercise 1: Die Roll Simulation &amp; Statistics <p>1. Overview &amp; Purpose Simulate 1,000 rolls of a fair six\u2011sided die in Python and compute the empirical mean and variance. Why: Reinforces theoretical vs. empirical probability, builds NumPy familiarity, and demonstrates sampling variability.</p> <p>2. Concept Reinforcement - Probability &amp; random variables - Expectation (mean) &amp; variance - Sampling variability / Law of Large Numbers</p> <p>3. Real\u2011World Relevance - Quality control: simulate defect rates in a batch - Risk modeling: Monte Carlo estimates of portfolio variance - Game design: balance randomness in mechanics</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\n\n# Simulate 1,000 die rolls\nnp.random.seed(42)           # optional: reproducibility\nrolls = np.random.randint(1, 7, size=1000)\n\n# Compute statistics\nmean_rolls = rolls.mean()\nvar_rolls  = rolls.var()\n\nprint(\"Simulated Mean:    \", mean_rolls)\nprint(\"Simulated Variance:\", var_rolls)\n</code></pre></p> <p>Notes: - <code>np.random.randint(1, 7, size=1000)</code> \u2192 integers 1\u20136 - <code>.mean()</code>, <code>.var()</code> \u2192 empirical mean &amp; variance (population variance by default)</p> <p>5. Expected Outcomes &amp; Interpretation - Mean \u2248 3.5, Variance \u2248 2.92 (\u00b1 sampling noise) - Larger sample sizes converge closer to the theoretical values</p> <p>6. Extensions &amp; Variations - Try sample sizes 100, 10,000 and compare stats - Simulate a weighted/unfair die - Plot histogram with <code>matplotlib</code></p> <p>7. Additional Notes &amp; Tips - Use <code>np.random.seed(...)</code> if you want the same results every run - Avoid Python loops when possible\u2014NumPy vectorization is faster</p> Exercise 2: Coin Flip Probability Estimation <p>1. Overview &amp; Purpose Simulate 10,000 coin flips to estimate the probability of heads and tails.</p> <p>2. Concept Reinforcement - Discrete random variables - Empirical vs. theoretical probability</p> <p>3. Real\u2011World Relevance - A/B testing: success/failure rates - Clinical trials: treatment vs. control outcomes</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\n\nnp.random.seed(0)                      # optional: reproducibility\nflips = np.random.choice(['H', 'T'], size=10000)\n\np_heads = np.mean(flips == 'H')\np_tails = np.mean(flips == 'T')\n\nprint(f\"P(heads): {p_heads:.3f}, P(tails): {p_tails:.3f}\")\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - Both \u2248 0.5, with random fluctuation ~\u00b10.01 - Larger samples narrow the gap to 0.5</p> <p>6. Extensions &amp; Variations - Weighted coin: <code>p=['H':0.3, 'T':0.7]</code> - Plot counts with a bar chart</p> <p>7. Additional Notes &amp; Tips - Set <code>np.random.seed(...)</code> when you want reproducible runs</p> Exercise 3: Histogram of Die Rolls <p>1. Overview &amp; Purpose Visualize the distribution of the 1,000 die rolls from Exercise\u202f1.</p> <p>2. Concept Reinforcement - Frequency vs. probability - Basic data visualization</p> <p>3. Real\u2011World Relevance - Sales distribution by category - Error counts per batch in manufacturing</p> <p>4. Step-by-Step Instructions <pre><code>import matplotlib.pyplot as plt\n\nplt.hist(rolls, bins=range(1, 8), align='left', rwidth=0.8)\nplt.xlabel('Die Face')\nplt.ylabel('Frequency')\nplt.title('Histogram of 1,000 Die Rolls')\nplt.show()\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - Bars roughly equal for faces 1\u20136 (random noise is okay)</p> <p>6. Extensions &amp; Variations - Normalized histogram: <code>plt.hist(..., density=True)</code> - Overlay the theoretical PMF as a line/bar plot</p> <p>7. Additional Notes &amp; Tips - <code>bins=range(1,8)</code> centers bars on integer faces - If you reused <code>rolls</code> from Exercise\u202f1, you don\u2019t need to re\u2011simulate</p> Exercise 4: Exponential Distribution Simulation <p>1. Overview &amp; Purpose Simulate 5,000 samples from an exponential distribution (mean\u202f=\u202f2) and compute mean/variance.</p> <p>2. Concept Reinforcement - Continuous random variables - Relationship between distribution parameters and statistics</p> <p>3. Real\u2011World Relevance - Time between machine failures - Call\u2011center interarrival times</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\n\nnp.random.seed(0)                         # optional\nsamples = np.random.exponential(scale=2, size=5000)\n\nprint(\"Empirical Mean:   \", samples.mean())\nprint(\"Empirical Variance:\", samples.var())\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - Mean \u2248 2 - Variance \u2248 4 Small deviations are normal due to randomness.</p> <p>6. Extensions &amp; Variations - Change <code>scale</code> (mean) parameter - Plot histogram and overlay the theoretical PDF</p> <p>7. Additional Notes &amp; Tips - <code>scale</code> in NumPy\u2019s exponential is ( 1/\u03bb ) (i.e., the mean) - Use <code>matplotlib</code> or <code>seaborn</code> for quick visual checks</p> Exercise 5: Normal Distribution Sampling <p>1. Overview &amp; Purpose Draw 10,000 samples from a standard normal distribution (mean\u202f0, \u03c3\u202f=\u202f1) and verify statistics.</p> <p>2. Concept Reinforcement - Properties of the Gaussian distribution - Central Limit Theorem (preview)</p> <p>3. Real\u2011World Relevance - Measurement error modeling - Standardized test scores / z\u2011scores</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\n\nnp.random.seed(0)                    # optional\nnormals = np.random.randn(10000)     # mean=0, std=1\n\nprint(\"Mean:\", normals.mean())\nprint(\"Variance:\", normals.var())\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - Mean \u2248 0, Variance \u2248 1 (allow small deviation)</p> <p>6. Extensions &amp; Variations - Use <code>np.random.normal(loc, scale, size)</code> for non\u2011standard normals - Make a QQ plot vs. theoretical normal to check normality</p> <p>7. Additional Notes &amp; Tips - <code>plt.hist(normals, density=True)</code> to visualize the bell curve</p> Exercise 6: Sampling Distribution of the Mean <p>1. Overview &amp; Purpose Run 1,000 \u201cmini\u2011experiments.\u201d Each experiment rolls a die 100 times, records the mean, and we plot the distribution of those means.</p> <p>2. Concept Reinforcement - Law of Large Numbers - Sampling variability decreases as sample size increases - Sampling distribution &amp; standard error</p> <p>3. Real\u2011World Relevance - Polling averages: many small samples \u2192 distribution of means - Quality control: batch averages instead of single measurements</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)  # optional\nmeans = [np.random.randint(1, 7, 100).mean() for _ in range(1000)]\n\nplt.hist(means, bins=20)\nplt.title('Sampling Distribution of Die Roll Means')\nplt.xlabel('Sample Mean')\nplt.ylabel('Frequency')\nplt.show()\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - Histogram looks roughly normal, centered near 3.5 - Spread is much narrower than individual die outcomes</p> <p>6. Extensions &amp; Variations - Change experiment size: n=10 vs. n=1000 \u2192 compare spreads - Compute standard error: \u03c3 / \u221an (use \u03c3 \u2248 1.71 for a die)</p> <p>7. Additional Notes &amp; Tips - List comprehensions are fine here; for speed, you can vectorize with NumPy</p> Exercise 7: Weighted Dice Simulation <p>1. Overview &amp; Purpose Simulate 1,000 rolls of a biased die where P(6) = 0.5 and the other faces share the remaining probability.</p> <p>2. Concept Reinforcement - Custom discrete distributions - How bias shifts mean and variance</p> <p>3. Real\u2011World Relevance - Biased processes in manufacturing (defect more likely on one line) - Skewed customer behavior (one product far more popular)</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\n\nnp.random.seed(0)  # optional\nfaces = [1, 2, 3, 4, 5, 6]\nprobs = [0.1]*5 + [0.5]     # 0.1 each for 1\u20135, 0.5 for 6\nrolls_biased = np.random.choice(faces, size=1000, p=probs)\n\nprint(\"Mean:\", rolls_biased.mean(), \"Variance:\", rolls_biased.var())\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - Mean &gt; 3.5 due to heavy weight on 6 - Variance will differ from the fair\u2011die case</p> <p>6. Extensions &amp; Variations - Tweak <code>probs</code> for different biases - Plot histograms for fair vs. biased dice side\u2011by\u2011side</p> <p>7. Additional Notes &amp; Tips - Ensure <code>sum(probs) == 1</code> or NumPy will error - You can simulate many biased scenarios to stress\u2011test models</p> Exercise 8: Vector Addition &amp; Scaling <p>1. Overview &amp; Purpose Demonstrate vector addition and scalar multiplication using simple feature vectors.</p> <p>2. Concept Reinforcement - Vector space operations (add, scale) - Geometric interpretation (direction &amp; length)</p> <p>3. Real\u2011World Relevance - Combine feature effects (e.g., marketing channels) - Scale normalized data or weights</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\n\nv1 = np.array([2, 4, 6])\nv2 = np.array([1, 3, 5])\n\nsum_v   = v1 + v2        # vector addition\nscaled_v = 0.5 * v1      # scalar multiplication\n\nprint(\"Sum:   \", sum_v)\nprint(\"Scaled:\", scaled_v)\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - <code>Sum</code> = <code>[3, 7, 11]</code> - <code>Scaled</code> = <code>[1, 2, 3]</code></p> <p>6. Extensions &amp; Variations - Compute the dot product: <code>v1.dot(v2)</code> - Visualize 2D/3D vectors (e.g., with matplotlib quiver)</p> <p>7. Additional Notes &amp; Tips - Ensure vectors have the same length for element\u2011wise ops - Scalar multiplication stretches/shrinks the vector length</p> Exercise 9: Matrix Multiplication Demonstration <p>1. Overview &amp; Purpose Multiply a 2\u00d73 matrix by a 3\u00d72 matrix to reinforce matrix\u2011multiplication rules and shape compatibility.</p> <p>2. Concept Reinforcement - Shape rules (inner dimensions must match) - Summation over the inner index (k)</p> <p>3. Real\u2011World Relevance - Transforming feature spaces - Chaining layers in neural networks (each layer = a matrix multiply)</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\n\nA = np.array([[1, 2, 3],\n              [4, 5, 6]])          # shape (2, 3)\n\nB = np.array([[ 7,  8],\n              [ 9, 10],\n              [11, 12]])          # shape (3, 2)\n\nC = A.dot(B)            # or: C = A @ B in Python 3.5+\nprint(\"Result:\\n\", C)\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation <pre><code>[[ 58  64]\n [139 154]]\n</code></pre> - You can verify: first row \u00d7 first column \u2192 17 + 29 + 3*11 = 58</p> <p>6. Extensions &amp; Variations - Try <code>B @ A</code> to see the shape error - Use larger random matrices to test performance</p> <p>7. Additional Notes &amp; Tips - Check shapes with <code>A.shape</code>, <code>B.shape</code> - <code>@</code> is shorthand for matrix multiply (<code>dot</code>) in NumPy/Python 3.5+</p> Exercise 10: PCA on Toy Dataset <p>1. Overview &amp; Purpose Perform PCA on a tiny 2\u2011D dataset, reduce it to 1\u2011D, and see how much variance is captured.</p> <p>2. Concept Reinforcement - Eigenvectors / eigenvalues - Dimensionality reduction &amp; variance explained</p> <p>3. Real\u2011World Relevance - Compressing image or sensor data - Feature extraction before clustering or modeling</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([\n    [2.5, 2.4],\n    [0.5, 0.7],\n    [2.2, 2.9],\n    [1.9, 2.2],\n    [3.1, 3.0]\n])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint(\"Explained variance ratio:\", pca.explained_variance_ratio_)\nprint(\"Projected data:\\n\", X_pca)\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - First component should capture ~98% of variance for this toy set - Projected 1\u2011D data preserves most \u201cinformation\u201d (spread)</p> <p>6. Extensions &amp; Variations - Plot original 2\u2011D vs. projected 1\u2011D points - Try <code>n_components=2</code> (no reduction) and inspect components</p> <p>7. Additional Notes &amp; Tips - Requires <code>scikit-learn</code> (<code>pip install scikit-learn</code> if missing) - PCA assumes linear structure; nonlinear data may need t\u2011SNE/UMAP</p>"},{"location":"week-1/#6-week-1-summary-what-you-can-now-do","title":"6. Week\u202f1 Summary &amp; What You Can Now Do","text":"<p>You can now\u2026</p> <ul> <li>Explain key AI milestones: Dartmouth (1956), Expert Systems (1970s\u201380s), Deep Learning boom (2010s\u2013present) and why each wave mattered.  </li> <li>Use probability concepts (random variables, mean, variance) and verify them empirically in Python.  </li> <li>Work with basic linear algebra objects (vectors, matrices, dot products, matrix multiplication) and see how they power ML models.  </li> <li>Install and run core tools (Anaconda, Jupyter, NumPy, pandas) to explore data and math interactively.</li> </ul>"},{"location":"week-1/#a-ai-history-in-one-breath","title":"A. AI History in One Breath","text":"<ul> <li>Dartmouth Workshop (1956): coined \u201cAI\u201d; optimism about simulating intelligence. Lesson: Ambition vs. realism\u2014avoid hype traps.  </li> <li>Expert Systems (\u201970s\u2013\u201980s): rule-based IF\u2013THEN logic (e.g., MYCIN). Lesson: Transparency is great, but brittle without probabilities.  </li> <li>Deep Learning (2010s\u2013): data + GPUs + better algorithms (AlexNet etc.) \u2192 breakthroughs. Lesson: Modern toolkits (TensorFlow/PyTorch) center on neural nets.</li> </ul>"},{"location":"week-1/#b-probability-from-intuition-to-math","title":"B. Probability: From Intuition to Math","text":"<ul> <li>Random Variables: discrete (die, coin), continuous (time-to-failure).  </li> <li>Expectation &amp; Variance: long-run average and spread\u2014computed by hand and via NumPy.  </li> <li>Why it matters: Loss functions, risk estimation, feature engineering all use these ideas.  </li> <li>Real world ties: A/B tests, forecasting demand spikes, Monte Carlo risk simulations.</li> </ul> <p>Anchor formulas</p> <ul> <li>Discrete mean: \\(E[X] = \\sum x_i P(X=x_i)\\)  </li> <li>Variance: \\(\\mathrm{Var}(X) = E[(X - E[X])^2]\\)</li> </ul>"},{"location":"week-1/#c-linear-algebra-the-language-of-ml","title":"C. Linear Algebra: The Language of ML","text":"<ul> <li>Vectors: feature lists (e.g., <code>[age, spend, orders]</code>).  </li> <li>Matrices: batches of vectors; all your data at once.  </li> <li>Dot Product: core of regression and neuron activations.  </li> <li>Matrix Multiplication: chaining transformations (layers) in neural nets.  </li> <li>Why it matters: Speed (GPU vectorization), interpretability (weights are matrices), compression (PCA).</li> </ul>"},{"location":"week-1/#d-tools-workflow-locked-in","title":"D. Tools &amp; Workflow Locked In","text":"<ul> <li>Anaconda &amp; Jupyter: you spun up a notebook and ran code.  </li> <li>NumPy/pandas: you handled arrays, stats, and basic data manipulation.  </li> <li>Workflow habits: preview locally (<code>mkdocs serve</code>), commit/push, deploy (<code>gh-deploy</code>).</li> </ul>"},{"location":"week-1/#e-exercises-recap-what-each-taught-you","title":"E. Exercises Recap (What each taught you)","text":"Exercise Core Idea Concept Reinforced Real\u2011World Parallel 1. Die roll stats Empirical vs. theoretical Mean, variance, sampling noise QC sampling, Monte Carlo 2. Coin flips Bernoulli trials Discrete RVs, proportions A/B tests, pass/fail outcomes 3. Histogram Visual distributions Frequency vs. prob., plotting Category sales distributions 4. Exponential sim Time-to-event model Continuous RVs, \u03bb &amp; scale Failure rates, wait times 5. Normal samples Gaussian basics CLT preview, z-scores Measurement error, scores 6. Sampling means Distribution of means Law of Large Numbers Polling averages, batch metrics 7. Weighted die Biased distributions Shifted mean/var, custom PMFs Skewed demand, unfair odds 8. Vector ops Add/scale vectors Vector spaces Feature scaling, weight tuning 9. Matrix multiply Shapes &amp; transforms Linear maps, dot sums NN layers, feature transforms 10. PCA toy data Dimensionality reduction Eigenvectors/variance explained Data compression, preprocessing"},{"location":"week-1/#7-additional-resources","title":"7. Additional Resources","text":"<p>Probability &amp; Statistics</p> <ul> <li>Khan Academy \u2013 Introduction to Probability   Beginner\u2011friendly videos and practice problems. https://www.khanacademy.org/math/statistics-probability/probability-library</li> <li>Seeing Theory (Brown University)   Interactive visual explanations of probability concepts. https://seeing-theory.brown.edu/</li> </ul> <p>Linear Algebra</p> <ul> <li>3Blue1Brown \u2013 Essence of Linear Algebra (YouTube series)   Beautiful visuals for vectors, matrices, dot products, eigenvectors. https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr</li> <li>Khan Academy \u2013 Linear Algebra   Step\u2011by\u2011step lessons with exercises. https://www.khanacademy.org/math/linear-algebra</li> </ul> <p>Python, NumPy &amp; pandas</p> <ul> <li>Official Python Docs \u2013 Syntax, stdlib, tutorials. https://docs.python.org/3/</li> <li>NumPy User Guide \u2013 Arrays, broadcasting, linear algebra. https://numpy.org/doc/stable/user/</li> <li>pandas Getting Started \u2013 DataFrames, cleaning, transforms. https://pandas.pydata.org/docs/getting_started/index.html</li> </ul> <p>AI History &amp; Overviews</p> <ul> <li>\u201cCompeting in the Age of AI\u201d (Iansiti &amp; Lakhani) \u2013 Ch.\u202f1\u20133 (already on your list) </li> <li>\u201cDeep Learning\u201d (Goodfellow, Bengio, Courville) \u2013 Intro &amp; Ch.\u202f6\u20137 (free online) https://www.deeplearningbook.org/</li> </ul> <p>Visualization &amp; Math Intuition</p> <ul> <li>Matplotlib Gallery \u2013 Quick plot recipes. https://matplotlib.org/stable/gallery/index.html</li> <li>Desmos Graphing Calculator \u2013 Fast function plots and geometry. https://www.desmos.com/calculator</li> </ul> <p>Bonus Cheat Sheets</p> <ul> <li>Markdown Syntax Cheat Sheet (for editing your site) https://www.markdownguide.org/cheat-sheet/</li> <li>NumPy/Pandas one\u2011pagers (various printable PDFs) https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf https://www.dataquest.io/blog/numpy-cheat-sheet/</li> </ul>"},{"location":"week-2/","title":"Week 2 Lesson Plan \u2014 Supervised Learning: Regression &amp; Classification","text":""},{"location":"week-2/#1-lesson-overview","title":"1. Lesson Overview","text":"<p>Learning Objectives By the end of Week\u202f2, you will be able to:</p> <ul> <li>Explain what supervised learning is and how it differs from unsupervised learning.  </li> <li>Build and evaluate linear regression and logistic regression models using scikit\u2011learn.  </li> <li>Understand and compute key evaluation metrics (MSE, MAE, R\u00b2 for regression; Accuracy, Precision, Recall, F1, ROC\u2013AUC for classification).  </li> <li>Recognize overfitting vs. underfitting and apply basic remedies (train/test split, regularization).  </li> <li>Implement a clean ML workflow: load data \u2192 split \u2192 train \u2192 evaluate \u2192 iterate.</li> </ul>"},{"location":"week-2/#2-core-definitions","title":"2. Core Definitions","text":"Term Definition &amp; Example Supervised Learning Learning a mapping from inputs X to an output y using labeled data. Example: Predicting house price (y) from size and bedrooms (X). Regression Supervised learning where y is numeric/continuous. Example: Predicting steel prices or monthly revenue. Classification Supervised learning where y is categorical. Example: Predicting if a lead will convert (\u201cyes/no\u201d). Loss Function A formula that measures how wrong a prediction is. Models try to minimize this. Example: Mean Squared Error (MSE). Overfitting / Underfitting Overfitting: model memorizes noise, performs poorly on new data. Underfitting: model too simple, misses patterns. Train/Test Split Partition data into a training set (to fit the model) and test set (to evaluate generalization). Precision / Recall / F1 Metrics for classification. Precision: \u201cOf predicted positives, how many were right?\u201d Recall: \u201cOf actual positives, how many did we catch?\u201d F1 balances both."},{"location":"week-2/#3-concept-sections","title":"3. Concept Sections","text":""},{"location":"week-2/#a-supervised-learning-big-picture","title":"A. Supervised Learning: Big Picture","text":"<p>A1. Introduction (Plain English) - Supervised learning is teaching by example. You give the algorithm many input\u2013output pairs, and it learns the relationship. - Two main flavors:   - Regression: Predict numbers (price, demand).   - Classification: Predict categories (spam/not spam, churn/no churn).</p> <p>A2. The Basic Pipeline 1. Collect &amp; clean data (features X, target y) 2. Split into training and test sets 3. Train a model on training data 4. Evaluate on test data (metrics) 5. Tune hyperparameters or choose another model 6. Deploy/Use the model</p>"},{"location":"week-2/#b-linear-regression-deep-dive","title":"B. Linear Regression Deep Dive","text":"<p>B1. Intuition (Grade\u201110 friendly) - Plot points on a graph (e.g., ad spend vs. sales). Draw the \u201cbest\u201d straight line through them. - \u201cBest\u201d usually = the line with the smallest average squared error.</p> <p>B2. Formalism - Model: \\(\\hat{y} = w_0 + w_1 x_1 + \\dots + w_n x_n\\) - MSE: \\(\\frac{1}{m}\\sum_{i=1}^m (\\hat{y}_i - y_i)^2\\)</p> <p>B3. Why You Care - Baseline model for many business problems. - Builds intuition for linear layers in neural networks later.</p>"},{"location":"week-2/#c-logistic-regression-classification","title":"C. Logistic Regression (Classification)","text":"<p>C1. Intuition (Plain English) - Linear combo of features \u2192 pass through sigmoid to get probability (0\u20131). - Threshold (e.g., 0.5) to decide class.</p> <p>C2. Formal Bits - Sigmoid: \\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\), where \\(z = w^\\top x + b\\). - Cross\u2011entropy loss penalizes confident wrong predictions more.</p> <p>C3. Odds &amp; Log\u2011Odds - Logistic regression models log\u2011odds: \\(\\log \\frac{p}{1-p} = w^\\top x + b\\). - Coefficients show how features push probability up/down.</p>"},{"location":"week-2/#d-evaluation-metrics-overfitting","title":"D. Evaluation Metrics &amp; Overfitting","text":"<p>D1. Regression Metrics - MSE / RMSE: Squared errors (sensitive to outliers). - MAE: Absolute errors (robust to outliers). - R\u00b2: Variance explained.</p> <p>D2. Classification Metrics - Accuracy: Overall correctness (misleading on imbalance). - Precision / Recall / F1: Balance false positives vs. false negatives. - ROC\u2013AUC: Performance across thresholds.</p> <p>D3. Overfitting vs. Underfitting - Overfit: Great on train, bad on test. - Underfit: Bad everywhere. - Fixes: More data, simpler model, regularization (L1/L2), cross\u2011validation.</p>"},{"location":"week-2/#4-tools-installation-setup-week-2-specific","title":"4. Tools Installation &amp; Setup (Week\u202f2 Specific)","text":"<p>Assumes Python, Jupyter, NumPy, and pandas are already installed from Week\u202f1.</p>"},{"location":"week-2/#a-download-install-only-if-you-dont-already-have-them","title":"A. Download / Install (only if you don\u2019t already have them)","text":"<ul> <li>Python 3.x (official): https://www.python.org/downloads/ </li> <li>Anaconda (optional, easier package management): https://www.anaconda.com/download </li> <li>Git (already on your machine; link for reference): https://git-scm.com/downloads </li> <li>scikit-learn docs: https://scikit-learn.org/stable/install.html </li> <li>matplotlib install guide: https://matplotlib.org/stable/users/installing.html </li> <li>seaborn install guide (optional): https://seaborn.pydata.org/installing.html</li> </ul>"},{"location":"week-2/#b-install-scikit-learn-matplotlib","title":"B. Install scikit-learn &amp; matplotlib","text":"<p>Pick ONE method (conda or pip).</p> <p>Using conda (recommended if you installed Anaconda):</p> <pre><code>conda install scikit-learn matplotlib -y\n</code></pre> <p>Or with pip (pure Python):</p> <pre><code>pip install scikit-learn matplotlib\n# Windows fallback if 'pip' isn\u2019t recognized:\npy -m pip install scikit-learn matplotlib\n</code></pre>"},{"location":"week-2/#c-optional-install-seaborn-for-nicer-plots","title":"C. (Optional) Install seaborn for nicer plots","text":"<p>With conda:</p> <pre><code>conda install seaborn -y\n</code></pre> <p>Or with pip:</p> <pre><code>pip install seaborn\npy -m pip install seaborn\n</code></pre>"},{"location":"week-2/#d-verify-installs-inside-pythonjupyter","title":"D. Verify installs inside Python/Jupyter","text":"<pre><code>import sklearn, matplotlib, seaborn\nprint(\"sklearn:\", sklearn.__version__)\nprint(\"matplotlib:\", matplotlib.__version__)\nprint(\"seaborn:\", seaborn.__version__)\n</code></pre>"},{"location":"week-2/#e-why-these-tools","title":"E. Why these tools?","text":"<ul> <li>scikit-learn \u2013 Core classic ML toolkit (linear/logistic regression, train/test split, GridSearchCV).  </li> <li>matplotlib \u2013 Base plotting library (residual plots, ROC curves, confusion matrices).  </li> <li>seaborn (optional) \u2013 Cleaner statistical charts (pairplots, heatmaps) built on matplotlib.  </li> <li>joblib (bundled with scikit-learn) \u2013 Quick model save/load.</li> </ul>"},{"location":"week-2/#f-troubleshooting","title":"F. Troubleshooting","text":"<pre><code># 'pip' not found\npython -m pip install --upgrade pip\n\n# 'conda' not found\n# You probably didn\u2019t install Anaconda or its PATH isn\u2019t set. Use pip instead.\n\n# Permission error on Windows\n# Open \"Anaconda Prompt\" (Start Menu) or run PowerShell as Administrator\n\n# Still stuck? Try upgrading tools\npip install --upgrade scikit-learn matplotlib seaborn\n</code></pre>"},{"location":"week-2/#5-step-by-step-exercises-10-total","title":"5 \u2014 Step-by-Step Exercises (10 total)","text":""},{"location":"week-2/#5-step-by-step-exercises","title":"5. Step by Step Exercises","text":"<p>Same template as Week\u202f1: Purpose \u2192 Concept \u2192 Real\u2011World \u2192 Steps \u2192 Expected Outcome \u2192 Extensions \u2192 Notes.</p>"},{"location":"week-2/#regression-exercises-14","title":"Regression (Exercises 1\u20134)","text":"Exercise 1: Simple Linear Regression (Synthetic Data) <p>1. Overview &amp; Purpose Fit a linear regression on generated data (<code>y = 3x + noise</code>) to see how the model recovers the relationship.</p> <p>2. Concept Reinforcement - Linear regression basics - Train/test split, MSE, R\u00b2</p> <p>3. Real\u2011World Relevance - Forecasting revenue vs. ad spend - KPI prediction</p> <p>4. Step-by-Step Instructions <pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10\ny = 3 * X.squeeze() + np.random.randn(100) * 2\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nmodel = LinearRegression().fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"MSE:\", mse)\nprint(\"R\u00b2 :\", r2)\nprint(\"Coef:\", model.coef_, \"Intercept:\", model.intercept_)\n</code></pre></p> <p>5. Expected Outcomes &amp; Interpretation - Slope \u2248 3; high R\u00b2.  </p> <p>6. Extensions &amp; Variations - Increase noise - Add polynomial features</p> <p>7. Notes - Always keep a test set to gauge generalization.</p> Exercise 2: Visualizing Fit &amp; Residuals <p>Purpose: See where the model makes errors. Concepts: Residual plots reveal structure; random scatter = good.</p> <pre><code>import matplotlib.pyplot as plt\n\n# Uses X_test, y_test, y_pred, model from Exercise 1\nplt.scatter(X_test, y_test, label='Actual')\nplt.scatter(X_test, y_pred, label='Predicted')\nplt.plot(sorted(X_test[:,0]), model.predict(np.sort(X_test, axis=0)), color='red', label='Line')\nplt.legend(); plt.title(\"Actual vs. Predicted\")\nplt.show()\n\nresiduals = y_test - y_pred\nplt.scatter(y_pred, residuals)\nplt.axhline(0, color='red', linestyle='--')\nplt.xlabel(\"Predicted\"); plt.ylabel(\"Residual\")\nplt.title(\"Residual Plot\")\nplt.show()\n</code></pre> <p>Expected: Residuals roughly centered around 0 with no clear pattern. Extensions: Histogram of residuals; log-transform y if needed.</p> Exercise 3: Multiple Linear Regression with pandas <p>Purpose: Use several features to predict a target. Concepts: Multivariate regression, MAE.</p> <pre><code>import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\ndata = {\n    'size': [1400,1600,1700,1875,1100,1550,2350,2450,1425,1700],\n    'bedrooms': [3,3,3,2,2,3,4,4,3,3],\n    'age': [20,15,18,12,30,15,7,5,24,18],\n    'price': [245000,312000,279000,308000,199000,219000,405000,324000,319000,255000]\n}\ndf = pd.DataFrame(data)\n\nX = df[['size','bedrooms','age']]\ny = df['price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nlr = LinearRegression().fit(X_train, y_train)\npreds = lr.predict(X_test)\nmae = mean_absolute_error(y_test, preds)\n\nprint(\"Coefficients:\", lr.coef_)\nprint(\"Intercept:\", lr.intercept_)\nprint(\"MAE:\", mae)\n</code></pre> <p>Expected: Reasonable MAE; coefficients show feature influence. Extensions: Standardize features; add interaction terms. Notes: Watch multicollinearity.</p> Exercise 4: Polynomial Regression &amp; Overfitting Demo <p>Purpose: Show how higher-degree polynomials can overfit. Concepts: Bias\u2013variance trade\u2011off.</p> <pre><code>import numpy as np, matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nnp.random.seed(0)\nX = np.linspace(0, 1, 20).reshape(-1,1)\ny = np.sin(2*np.pi*X).ravel() + np.random.randn(20)*0.2\n\nfor degree in [1, 3, 9]:\n    poly = PolynomialFeatures(degree)\n    X_poly = poly.fit_transform(X)\n    model = LinearRegression().fit(X_poly, y)\n    y_pred = model.predict(X_poly)\n    mse = mean_squared_error(y, y_pred)\n    plt.scatter(X, y, label='data' if degree==1 else None)\n    plt.plot(X, y_pred, label=f'deg {degree} (MSE={mse:.2f})')\nplt.legend(); plt.show()\n</code></pre> <p>Expected: deg=1 underfits, deg=9 overfits. Extensions: Add train/test split; try Ridge/Lasso. Notes: Visual demos make concepts stick.</p>"},{"location":"week-2/#classification-exercises-57","title":"Classification (Exercises 5\u20137)","text":"Exercise 5: Logistic Regression on a Toy Dataset <p>Purpose: Fit logistic regression and read metrics. Concepts: Classification, probabilities, classification_report.</p> <pre><code>import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\nX, y = make_classification(n_samples=500, n_features=4, n_informative=2, random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nclf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\npreds = clf.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, preds))\nprint(classification_report(y_test, preds))\n</code></pre> <p>Expected: Accuracy ~0.8\u20130.9; precision/recall shown. Extensions: Change threshold; class weights. Notes: Increase <code>max_iter</code> if convergence warning.</p> Exercise 6: Confusion Matrix &amp; ROC Curve <p>Purpose: Visualize errors and threshold performance. Concepts: Confusion matrix, ROC, AUC.</p> <pre><code>import matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_curve, auc\n\ndisp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)\nplt.title(\"Confusion Matrix\"); plt.show()\n\ny_prob = clf.predict_proba(X_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nroc_auc = auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.2f})\")\nplt.plot([0,1],[0,1],'k--')\nplt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\"); plt.legend(); plt.show()\n</code></pre> <p>Expected: Curved ROC; AUC &gt; 0.5. Extensions: Precision\u2013Recall curve for imbalance. Notes: Use multiple metrics.</p> Exercise 7: Class Imbalance &amp; Threshold Tuning <p>Purpose: Show why accuracy fails with rare positives. Concepts: Threshold tuning, precision/recall trade\u2011off.</p> <pre><code>from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_fscore_support\n\nX, y = make_classification(n_samples=1000, n_features=5, weights=[0.95, 0.05], random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nclf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\ny_probs = clf.predict_proba(X_test)[:,1]\n\nfor thresh in [0.5, 0.3, 0.1]:\n    preds = (y_probs &gt;= thresh).astype(int)\n    p, r, f1, _ = precision_recall_fscore_support(y_test, preds, average='binary', zero_division=0)\n    print(f\"Threshold {thresh}: precision={p:.2f}, recall={r:.2f}, f1={f1:.2f}\")\n</code></pre> <p>Expected: Lower threshold \u2192 higher recall, lower precision. Extensions: Class weights, PR curves. Notes: Choose threshold by business cost.</p>"},{"location":"week-2/#workflow-tuning-exercises-810","title":"Workflow &amp; Tuning (Exercises 8\u201310)","text":"Exercise 8: Cross-Validation vs. Single Split <p>Purpose: Compare metrics stability. Concepts: KFold, variance of scores.</p> <pre><code>from sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Reuse X, y from Exercise 1 or make new\nmodel = LinearRegression()\nkf = KFold(n_splits=5, shuffle=True, random_state=0)\nscores = cross_val_score(model, X, y, scoring='r2', cv=kf)\n\nprint(\"R\u00b2 scores:\", scores)\nprint(\"Mean R\u00b2:\", np.mean(scores), \"Std:\", np.std(scores))\n</code></pre> <p>Expected: Slight variation across folds. Extensions: cross_val_predict. Notes: Vital for limited data.</p> Exercise 9: Hyperparameter Tuning with GridSearchCV <p>Purpose: Systematically find best hyperparameters. Concepts: Grid search, scoring.</p> <pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge\n\nparams = {'alpha': [0.01, 0.1, 1, 10, 100]}\ngrid = GridSearchCV(Ridge(), params, scoring='neg_mean_squared_error', cv=5)\ngrid.fit(X, y)\n\nprint(\"Best params:\", grid.best_params_)\nprint(\"Best score (MSE):\", -grid.best_score_)\n</code></pre> <p>Expected: One alpha gives lowest MSE. Extensions: RandomizedSearchCV for speed. Notes: Don\u2019t overfit to validation by repeated peeking.</p> Exercise 10: Mini End\u2011to\u2011End Project <p>Purpose: Practice full pipeline on a real CSV. Concepts: Clean \u2192 Split \u2192 Train \u2192 Evaluate \u2192 Save.</p> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport joblib\n\ndf = pd.read_csv(\"your_data.csv\")  # replace with a real dataset\nX = df.drop(columns=['target'])\ny = df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nmodel = LinearRegression().fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))\n\njoblib.dump(model, \"model.joblib\")\n</code></pre> <p>Expected: Working model + <code>model.joblib</code> saved. Extensions: Use Pipeline/ColumnTransformer. Notes: Document steps for your capstone.</p> <p>You can now\u2026</p> <ul> <li>Build baseline models for regression and classification with scikit\u2011learn.  </li> <li>Choose appropriate metrics and interpret them in context (business costs, imbalance).  </li> <li>Diagnose over/underfitting and apply simple fixes (regularization, cross\u2011validation).  </li> <li>Run a full ML workflow end\u2011to\u2011end on small datasets.</li> </ul>"},{"location":"week-2/#6-week-2-summary-what-you-can-now-do","title":"6. Week 2 Summary &amp; What You Can Now Do","text":""},{"location":"week-2/#a-core-takeaways","title":"A. Core Takeaways","text":"<ul> <li>Supervised learning = labeled data, mapping X\u2192y.  </li> <li>Linear regression \u2192 numeric predictions; logistic regression \u2192 categorical predictions via probabilities.  </li> <li>Metrics matter: pick ones aligned with the problem (e.g., F1 for imbalance).  </li> <li>Generalization beats memorization.</li> </ul>"},{"location":"week-2/#b-practical-wins","title":"B. Practical Wins","text":"<ul> <li>You used GridSearchCV, cross\u2011validation, and plotted diagnostics.  </li> <li>You can prototype business ML problems quickly.</li> </ul>"},{"location":"week-2/#c-next-week-prep","title":"C. Next Week Prep","text":"<ul> <li>Skim Week\u202f3 (k\u2011means, PCA) to see unsupervised learning.  </li> <li>Get comfortable with pandas &amp; plotting\u2014visualizations increase.</li> </ul>"},{"location":"week-2/#7-additional-resources","title":"7. Additional Resources","text":"<p>Guides &amp; Tutorials</p> <ul> <li>scikit\u2011learn User Guide \u2013 Supervised Learning https://scikit-learn.org/stable/supervised_learning.html</li> <li>StatQuest (YouTube) \u2013 Excellent clear videos on regression, classification, metrics https://www.youtube.com/user/joshstarmer</li> </ul> <p>Metrics &amp; Evaluation</p> <ul> <li>\u201cPrecision, Recall and F1 Score for Dummies\u201d (various blog guides)  </li> <li>ROC &amp; AUC explainers (blog posts, Coursera ML course notes)</li> </ul> <p>Books &amp; Chapters</p> <ul> <li>An Introduction to Statistical Learning (ISLR) \u2013 Free PDF, chapters on regression &amp; classification https://www.statlearning.com/</li> </ul> <p>Cheat Sheets</p> <ul> <li>scikit\u2011learn, matplotlib, seaborn cheat sheets (quick Google finds)</li> </ul>"}]}