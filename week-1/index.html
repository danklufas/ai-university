
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../roadmap/">
      
      
        <link rel="next" href="../week-2/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.15">
    
    
      
        <title>Week 1 - AI University Curriculum</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#history-of-ai-math-foundations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AI University Curriculum" class="md-header__button md-logo" aria-label="AI University Curriculum" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI University Curriculum
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Week 1
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AI University Curriculum" class="md-nav__button md-logo" aria-label="AI University Curriculum" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    AI University Curriculum
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../roadmap/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Roadmap
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Weeks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Weeks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Week 1
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Week 1
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-lesson-overview" class="md-nav__link">
    <span class="md-ellipsis">
      1. Lesson Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-core-definitions" class="md-nav__link">
    <span class="md-ellipsis">
      2. Core Definitions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-concept-sections" class="md-nav__link">
    <span class="md-ellipsis">
      3. Concept Sections
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Concept Sections">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-ai-milestones" class="md-nav__link">
    <span class="md-ellipsis">
      A. AI Milestones
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c-probability-basics" class="md-nav__link">
    <span class="md-ellipsis">
      C. Probability Basics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="C. Probability Basics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#c1-gentle-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      C1. Gentle Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c2-formal-definitions-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      C2. Formal Definitions &amp; Deep Dive
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#d-linear-algebra-basics" class="md-nav__link">
    <span class="md-ellipsis">
      D. Linear Algebra Basics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="D. Linear Algebra Basics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#d1-gentle-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      D1. Gentle Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#d2-formal-definitions-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      D2. Formal Definitions &amp; Deep Dive
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-tools-installation-setup" class="md-nav__link">
    <span class="md-ellipsis">
      4. Tools Installation &amp; Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Tools Installation &amp; Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-install-python-anaconda-windows-mac" class="md-nav__link">
    <span class="md-ellipsis">
      A. Install Python &amp; Anaconda (Windows &amp; Mac)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#b-launch-jupyter-notebook" class="md-nav__link">
    <span class="md-ellipsis">
      B. Launch Jupyter Notebook
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c-install-import-numpy-pandas" class="md-nav__link">
    <span class="md-ellipsis">
      C. Install &amp; Import NumPy &amp; pandas
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-step-by-step-exercises" class="md-nav__link">
    <span class="md-ellipsis">
      5. Step by Step Exercises
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-week-1-summary-what-you-can-now-do" class="md-nav__link">
    <span class="md-ellipsis">
      6. Week 1 Summary &amp; What You Can Now Do
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Week 1 Summary &amp; What You Can Now Do">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-ai-history-in-one-breath" class="md-nav__link">
    <span class="md-ellipsis">
      A. AI History in One Breath
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#b-probability-from-intuition-to-math" class="md-nav__link">
    <span class="md-ellipsis">
      B. Probability: From Intuition to Math
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c-linear-algebra-the-language-of-ml" class="md-nav__link">
    <span class="md-ellipsis">
      C. Linear Algebra: The Language of ML
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#d-tools-workflow-locked-in" class="md-nav__link">
    <span class="md-ellipsis">
      D. Tools &amp; Workflow Locked In
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#e-exercises-recap-what-each-taught-you" class="md-nav__link">
    <span class="md-ellipsis">
      E. Exercises Recap (What each taught you)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-additional-resources" class="md-nav__link">
    <span class="md-ellipsis">
      7. Additional Resources
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../week-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../week-3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week 3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../week-4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week 4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../week-5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week 5
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../cheat-sheet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="history-of-ai-math-foundations">History of AI &amp; Math Foundations</h1>
<h2 id="1-lesson-overview">1. Lesson Overview</h2>
<div class="admonition sucess">
<p class="admonition-title">Learning Objectives</p>
</div>
<p>By the end of this lesson, you will be able to:</p>
<ul>
<li>Describe three pivotal AI milestones and their lasting impact.</li>
<li>Define Artificial Intelligence (AI), Machine Learning (ML), and Data Science with clear examples.</li>
<li>Understand probability fundamentals—random variables, expectation, variance—and compute them by hand and in Python.</li>
<li>Grasp key linear algebra concepts—vectors, matrices, dot products, matrix multiplication—and see how they underpin AI algorithms.</li>
<li>Install and launch the required tools (Python, Jupyter Notebook, NumPy, pandas) and execute basic code.</li>
</ul>
<hr />
<h2 id="2-core-definitions">2. Core Definitions</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Term</th>
<th style="text-align: left;">Definition &amp; Citation</th>
<th style="text-align: left;">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Artificial Intelligence (AI)</strong></td>
<td style="text-align: left;">“The science and engineering of making intelligent machines, especially intelligent computer programs.” — John McCarthy, 1956</td>
<td style="text-align: left;">A chatbot that interprets questions and crafts human‑like responses.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Machine Learning (ML)</strong></td>
<td style="text-align: left;">Algorithms that improve performance on tasks by learning from data rather than explicit programming.</td>
<td style="text-align: left;">A regression model that learns to predict steel prices from historical sales.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Data Science</strong></td>
<td style="text-align: left;">Interdisciplinary practice of using statistics, programming, and domain knowledge to extract insights from data.</td>
<td style="text-align: left;">Cleaning and visualizing e‑commerce logs to uncover purchasing trends.</td>
</tr>
</tbody>
</table>
<h2 id="3-concept-sections">3. Concept Sections</h2>
<h3 id="a-ai-milestones">A. AI Milestones</h3>
<details class="info" open="open">
<summary>The Dartmouth Workshop (1956)</summary>
<p><strong>What happened:</strong><br />
In summer 1956, John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon met at Dartmouth College to ask: <em>“Can machines simulate human intelligence?”</em> They coined <strong>“Artificial Intelligence”</strong> and proposed studying how machines might “learn from experience,” “make abstractions,” and “use language.”</p>
<p><strong>Context &amp; significance:</strong><br />
- Pre‑1956, computers = number crunchers. Dartmouth reframed them as <strong>potential thinking machines</strong>.<br />
- Sparked optimism (and funding) that small teams could crack “every aspect of learning.”</p>
</details>
<p><strong>First programs:</strong><br />
    - <strong>Logic Theorist (1955)</strong> – Newell &amp; Simon proved logic theorems with a program.<br />
    - <strong>General Problem Solver (1957)</strong> – Early universal reasoning attempt.</p>
<div class="highlight"><pre><span></span><code>!!! note &quot;Why this still matters&quot;
    - Understanding the **hype → disappointment → AI winters** cycle helps you stay realistic about today’s claims.  
    - Symbolic reasoning/search ideas from this era live on in **knowledge graphs** and **constraint solvers**.
</code></pre></div>
<hr />
<details class="info" open="open">
<summary>Expert Systems Era (1970s–1980s)</summary>
<p><strong>Core idea:</strong> Encode expert knowledge as <strong>IF–THEN rules</strong>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>IF symptom = fever AND symptom = rash
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>THEN suggest = measles
</code></pre></div>
<p><strong>MYCIN (1972–1980):</strong><br />
- ~600 rules to diagnose bacterial infections &amp; suggest antibiotics<br />
- Matched/surpassed human experts in blind tests</p>
<p><strong>Strengths vs. limits:</strong><br />
- ✅ Transparent logic (traceable to specific rules)<br />
- ❌ Hard to scale (thousands of hand‑written rules), weak with uncertainty</p>
<div class="admonition tip">
<p class="admonition-title">Modern relevance</p>
<ul>
<li>Rule‑based logic still used in finance/healthcare compliance.  </li>
<li>Today’s <strong>hybrid systems</strong>: rules for regulation + ML models for scoring.</li>
</ul>
</div>
</details>
<hr />
<details class="info" open="open">
<summary>Deep Learning Boom (2010s–Present)</summary>
<p><strong>Key breakthrough – AlexNet (2012):</strong><br />
- 8‑layer CNN, cut ImageNet error rate in half (1.2M images, 1,000 classes)<br />
- Used ReLU, dropout, and <strong>GPU training</strong>.</p>
<p><strong>Why deep learning emerged:</strong><br />
1. <strong>Data:</strong> Huge labeled datasets (images, text, speech)<br />
2. <strong>Compute:</strong> GPUs = fast parallel matrix ops<br />
3. <strong>Algorithms:</strong> Batch norm, better backprop, new architectures</p>
<p><strong>Transformative apps:</strong><br />
- Computer vision: self‑driving cars, medical imaging<br />
- NLP: translation, GPT‑style generation<br />
- Speech: voice assistants, real‑time translation</p>
<div class="admonition success">
<p class="admonition-title">Why this matters for you</p>
<ul>
<li>Modern frameworks (TensorFlow, PyTorch) are built around neural nets.  </li>
<li>Explains why later terms focus on coding deep models &amp; leveraging <strong>pretrained architectures</strong> quickly.</li>
</ul>
</div>
</details>
<h3 id="c-probability-basics">C. Probability Basics</h3>
<div class="admonition abstract">
<p class="admonition-title">Definition</p>
<p><strong>Probability Theory</strong> – “The mathematical framework for quantifying uncertainty and modeling random phenomena.”</p>
</div>
<h4 id="c1-gentle-introduction">C1. Gentle Introduction</h4>
<details class="tip" open="open">
<summary>1. What is Chance?</summary>
<p><strong>Analogy:</strong> Flipping a coin—two outcomes, but you can’t predict which.<br />
<strong>Key idea:</strong> Probability measures how likely something is (0 = impossible, 1 = certain).<br />
<strong>Example:</strong> A fair coin → P(heads) = 0.5.</p>
</details>
<details class="tip" open="open">
<summary>2. Simple Data &amp; Averages</summary>
<p><strong>Real example:</strong> Test scores: 80, 90, 70, 100, 60.<br />
<strong>Mean (average):</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>(80 + 90 + 70 + 100 + 60) / 5 = 80
</code></pre></div>
<strong>Why it matters:</strong> The mean tells you what’s “typical.”</p>
</details>
<details class="tip" open="open">
<summary>3. Measuring Spread (Variance)</summary>
<p><strong>Analogy:</strong> Scores all near 80% → small spread; scores all over the place → big spread.<br />
<strong>Steps (using the score list above):</strong>
1. Subtract the mean (80): e.g. 60 − 80 = −20<br />
2. Square them: (−20)² = 400<br />
3. Average the squares → variance ≈ 280<br />
4. Square root of variance → standard deviation ≈ 16.7<br />
<strong>Why we care:</strong> Spread tells you how consistent or noisy data is—critical for risk or quality control.</p>
</details>
<h4 id="c2-formal-definitions-deep-dive">C2. Formal Definitions &amp; Deep Dive</h4>
<details class="info" open="open">
<summary>1. Random Variables</summary>
<p>A <strong>random variable (RV)</strong> assigns numbers to random outcomes.</p>
<ul>
<li><strong>Discrete RV:</strong> countable values (die roll, number of returns)<br />
  Example: Fair die →<br />
  <div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>X ∈ {1,2,3,4,5,6},   P(X = k) = 1/6
</code></pre></div></li>
<li><strong>Continuous RV:</strong> any value in a range (time between failures)<br />
  Example: Exponential distribution for time ( t ≥ 0 ):<br />
  <div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>f(t) = λ e^{−λ t}
</code></pre></div></li>
</ul>
</details>
<details class="info" open="open">
<summary>2. Expectation (Mean)</summary>
<p>Long‑run average outcome if you repeat forever.</p>
<ul>
<li><strong>Discrete:</strong><br />
  <div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>E[X] = Σ x_i · P(X = x_i)
</code></pre></div></li>
<li><strong>Continuous:</strong><br />
  <div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>E[X] = ∫ x f(x) dx
</code></pre></div>
<strong>Worked example (die):</strong><br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>E[X] = (1+2+3+4+5+6) / 6 = 3.5
</code></pre></div>
<strong>Relevance:</strong> Loss functions (e.g., MSE) minimize expected error → expectation is baked into training.</li>
</ul>
</details>
<details class="info" open="open">
<summary>3. Variance &amp; Standard Deviation</summary>
<p><strong>Variance:</strong> average squared distance from the mean.<br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>Var(X) = E[(X − E[X])^2]
</code></pre></div>
<strong>Std. dev.:</strong><br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>σ = √Var(X)
</code></pre></div>
<strong>Die example:</strong><br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>Var ≈ 2.92,  σ ≈ 1.71
</code></pre></div>
<strong>Why it matters:</strong> Tells you how uncertain predictions are, helps build confidence intervals, drives anomaly detection.</p>
</details>
<div class="admonition note">
<p class="admonition-title">Why Probability Matters in AI</p>
<ul>
<li><strong>Model Training:</strong> Errors are expectations (means) over data.  </li>
<li><strong>Uncertainty:</strong> Variance underpins confidence, risk, anomaly flags.  </li>
<li><strong>Feature Engineering:</strong> Understanding distributions guides transformations (e.g., log scales for skewed data).</li>
</ul>
</div>
<h3 id="d-linear-algebra-basics">D. Linear Algebra Basics</h3>
<div class="admonition abstract">
<p class="admonition-title">Definition</p>
<p><strong>Linear Algebra</strong> – “The branch of mathematics concerned with vectors, vector spaces, and linear transformations.”</p>
</div>
<h4 id="d1-gentle-introduction">D1. Gentle Introduction</h4>
<details class="tip" open="open">
<summary>1. Vectors as Lists</summary>
<p><strong>Analogy:</strong> A grocery list: <code>[2 bananas, 1 loaf bread, 500 g cheese]</code><br />
<strong>Key idea:</strong> A <strong>vector</strong> is just a list of numbers representing features.</p>
</details>
<details class="tip" open="open">
<summary>2. Matrices as Tables</summary>
<p><strong>Analogy:</strong> A seating chart (rows = tables, columns = seats):<br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>       S1  S2  S3
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>    T1  A   B   C
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>    T2  D   E   F
</code></pre></div>
<strong>Key idea:</strong> A <strong>matrix</strong> stacks many vectors into rows or columns.</p>
</details>
<details class="tip" open="open">
<summary>3. Dot Product Intuition</summary>
<p><strong>Example (bill splitting):</strong><br />
- You &amp; a friend order appetizers <code>[3, 2]</code> and drinks <code>[1, 2]</code>.<br />
- Prices: appetizers = \$5, drinks = \$2 →<br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>[3, 2] · [5, 2] = 3×5 + 2×2 = 19
</code></pre></div>
<strong>Why it matters:</strong> Same math as a simple regression prediction (weights × features).</p>
</details>
<details class="tip" open="open">
<summary>4. Real‑World Matrix Uses</summary>
<ul>
<li><strong>Recipe scaling:</strong> Multiply ingredient matrix by 1.5 to go from 4 to 6 servings.  </li>
<li><strong>School timetable:</strong> Days × hours grid to schedule classes.</li>
</ul>
</details>
<h4 id="d2-formal-definitions-deep-dive">D2. Formal Definitions &amp; Deep Dive</h4>
<details class="info" open="open">
<summary>1. Vectors &amp; Their Interpretation</summary>
<p>A vector <strong>x ∈ ℝⁿ</strong> is an ordered list of n numbers (features).<br />
<strong>Example:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>x = [age, monthly_spend, num_orders] = [45, 320.5, 12]
</code></pre></div></p>
</details>
<details class="info" open="open">
<summary>2. Matrices &amp; Batch Operations</summary>
<p>A matrix <strong>X ∈ ℝ^{m×n}</strong> stacks m row‑vectors of length n.<br />
<strong>Example (customer table):</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>X = [
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>  [45, 320.5, 12],
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>  [23, 150.0,  5],
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>  ...
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>]
</code></pre></div></p>
</details>
<details class="info" open="open">
<summary>3. Dot Product &amp; Linear Transformations</summary>
<p><strong>Dot product:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>a · b = Σ (a_i * b_i)
</code></pre></div>
<strong>Use in AI:</strong>
- <strong>Regression:</strong>  ŷ = w · x + b<br />
- <strong>Neural nets:</strong>  z = w · x + b, then apply activation (e.g., ReLU)</p>
</details>
<details class="info" open="open">
<summary>4. Matrix Multiplication</summary>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>C = A × B,   C_{ij} = Σ_k A_{ik} B_{kj}
</code></pre></div>
<strong>Example:</strong> Combine/transform features or chain neural network layers.</p>
</details>
<details class="success" open="open">
<summary>Why Linear Algebra Matters in AI</summary>
<ul>
<li><strong>Speed:</strong> GPUs/NumPy rely on vectorized (matrix) ops for efficiency.  </li>
<li><strong>Model Insight:</strong> Weights, activations, attention maps are matrices/vectors.  </li>
<li><strong>Dimensionality Reduction:</strong> PCA, SVD use eigenvectors/values to compress data.</li>
</ul>
</details>
<h2 id="4-tools-installation-setup">4. Tools Installation &amp; Setup</h2>
<div class="admonition info">
<p class="admonition-title">You’ll do this once, then reuse the environment all term.</p>
</div>
<h3 id="a-install-python-anaconda-windows-mac">A. Install Python &amp; Anaconda (Windows &amp; Mac)</h3>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="c1"># Visit this in your browser:</span>
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>https://www.anaconda.com/products/distribution
</code></pre></div>
1. Download the <strong>Python 3.x</strong> installer for your OS.<br />
2. Run the installer, accept defaults.<br />
3. Open <strong>Anaconda Navigator</strong> (Start Menu on Windows / Applications on Mac).</p>
<h3 id="b-launch-jupyter-notebook">B. Launch Jupyter Notebook</h3>
<ol>
<li>In Anaconda Navigator, click <strong>Launch</strong> under <strong>Jupyter Notebook</strong>.  </li>
<li>A browser window opens showing your files.  </li>
<li>Click <strong>New → Python 3</strong>.  </li>
<li>Rename it to <strong>Week1_AI_Math.ipynb</strong>.</li>
</ol>
<h3 id="c-install-import-numpy-pandas">C. Install &amp; Import NumPy &amp; pandas</h3>
<p>In a notebook cell, run:
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>!conda<span class="w"> </span>install<span class="w"> </span>numpy<span class="w"> </span>pandas<span class="w"> </span>-y
</code></pre></div>
Then import:
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
</code></pre></div></p>
<div class="admonition tip">
<p class="admonition-title">Why these tools?</p>
<ul>
<li><strong>Python/Jupyter:</strong> interactive coding &amp; math demos  </li>
<li><strong>NumPy:</strong> fast vectors/matrices (used everywhere in ML)  </li>
<li><strong>pandas:</strong> quick data tables, cleaning, summaries</li>
</ul>
</div>
<h2 id="5-step-by-step-exercises">5. Step by Step Exercises</h2>
<details class="example" open="open">
<summary>Exercise 1: Die Roll Simulation &amp; Statistics</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Simulate 1,000 rolls of a fair six‑sided die in Python and compute the empirical mean and variance.<br />
<strong>Why:</strong> Reinforces theoretical vs. empirical probability, builds NumPy familiarity, and demonstrates sampling variability.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Probability &amp; random variables<br />
- Expectation (mean) &amp; variance<br />
- Sampling variability / Law of Large Numbers</p>
<p><strong>3. Real‑World Relevance</strong><br />
- <strong>Quality control:</strong> simulate defect rates in a batch<br />
- <strong>Risk modeling:</strong> Monte Carlo estimates of portfolio variance<br />
- <strong>Game design:</strong> balance randomness in mechanics</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="c1"># Simulate 1,000 die rolls</span>
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>           <span class="c1"># optional: reproducibility</span>
<a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a><span class="n">rolls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<a id="__codelineno-19-6" name="__codelineno-19-6" href="#__codelineno-19-6"></a>
<a id="__codelineno-19-7" name="__codelineno-19-7" href="#__codelineno-19-7"></a><span class="c1"># Compute statistics</span>
<a id="__codelineno-19-8" name="__codelineno-19-8" href="#__codelineno-19-8"></a><span class="n">mean_rolls</span> <span class="o">=</span> <span class="n">rolls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<a id="__codelineno-19-9" name="__codelineno-19-9" href="#__codelineno-19-9"></a><span class="n">var_rolls</span>  <span class="o">=</span> <span class="n">rolls</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
<a id="__codelineno-19-10" name="__codelineno-19-10" href="#__codelineno-19-10"></a>
<a id="__codelineno-19-11" name="__codelineno-19-11" href="#__codelineno-19-11"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Simulated Mean:    &quot;</span><span class="p">,</span> <span class="n">mean_rolls</span><span class="p">)</span>
<a id="__codelineno-19-12" name="__codelineno-19-12" href="#__codelineno-19-12"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Simulated Variance:&quot;</span><span class="p">,</span> <span class="n">var_rolls</span><span class="p">)</span>
</code></pre></div></p>
<p><strong>Notes:</strong><br />
- <code>np.random.randint(1, 7, size=1000)</code> → integers 1–6<br />
- <code>.mean()</code>, <code>.var()</code> → empirical mean &amp; variance (population variance by default)</p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- Mean ≈ 3.5, Variance ≈ 2.92 (± sampling noise)<br />
- Larger sample sizes converge closer to the theoretical values</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Try sample sizes 100, 10,000 and compare stats<br />
- Simulate a <strong>weighted/unfair die</strong><br />
- Plot histogram with <code>matplotlib</code></p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- Use <code>np.random.seed(...)</code> if you want the same results every run<br />
- Avoid Python loops when possible—NumPy vectorization is faster</p>
</details>
<details class="example" open="open">
<summary>Exercise 2: Coin Flip Probability Estimation</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Simulate 10,000 coin flips to estimate the probability of heads and tails.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Discrete random variables<br />
- Empirical vs. theoretical probability</p>
<p><strong>3. Real‑World Relevance</strong><br />
- <strong>A/B testing:</strong> success/failure rates<br />
- <strong>Clinical trials:</strong> treatment vs. control outcomes</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                      <span class="c1"># optional: reproducibility</span>
<a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a><span class="n">flips</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>
<a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a><span class="n">p_heads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">flips</span> <span class="o">==</span> <span class="s1">&#39;H&#39;</span><span class="p">)</span>
<a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a><span class="n">p_tails</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">flips</span> <span class="o">==</span> <span class="s1">&#39;T&#39;</span><span class="p">)</span>
<a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a>
<a id="__codelineno-20-9" name="__codelineno-20-9" href="#__codelineno-20-9"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(heads): </span><span class="si">{</span><span class="n">p_heads</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, P(tails): </span><span class="si">{</span><span class="n">p_tails</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- Both ≈ 0.5, with random fluctuation ~±0.01<br />
- Larger samples narrow the gap to 0.5</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Weighted coin: <code>p=['H':0.3, 'T':0.7]</code><br />
- Plot counts with a bar chart</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- Set <code>np.random.seed(...)</code> when you want reproducible runs</p>
</details>
<details class="example" open="open">
<summary>Exercise 3: Histogram of Die Rolls</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Visualize the distribution of the 1,000 die rolls from Exercise 1.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Frequency vs. probability<br />
- Basic data visualization</p>
<p><strong>3. Real‑World Relevance</strong><br />
- Sales distribution by category<br />
- Error counts per batch in manufacturing</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">rolls</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Die Face&#39;</span><span class="p">)</span>
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Histogram of 1,000 Die Rolls&#39;</span><span class="p">)</span>
<a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- Bars roughly equal for faces 1–6 (random noise is okay)</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Normalized histogram: <code>plt.hist(..., density=True)</code><br />
- Overlay the theoretical PMF as a line/bar plot</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- <code>bins=range(1,8)</code> centers bars on integer faces<br />
- If you reused <code>rolls</code> from Exercise 1, you don’t need to re‑simulate</p>
</details>
<details class="example" open="open">
<summary>Exercise 4: Exponential Distribution Simulation</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Simulate 5,000 samples from an exponential distribution (mean = 2) and compute mean/variance.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Continuous random variables<br />
- Relationship between distribution parameters and statistics</p>
<p><strong>3. Real‑World Relevance</strong><br />
- Time between machine failures<br />
- Call‑center interarrival times</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                         <span class="c1"># optional</span>
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a><span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a>
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Empirical Mean:   &quot;</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Empirical Variance:&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">())</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- Mean ≈ 2<br />
- Variance ≈ 4<br />
Small deviations are normal due to randomness.</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Change <code>scale</code> (mean) parameter<br />
- Plot histogram and overlay the theoretical PDF</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- <code>scale</code> in NumPy’s exponential is ( 1/λ ) (i.e., the mean)<br />
- Use <code>matplotlib</code> or <code>seaborn</code> for quick visual checks</p>
</details>
<details class="example" open="open">
<summary>Exercise 5: Normal Distribution Sampling</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Draw 10,000 samples from a standard normal distribution (mean 0, σ = 1) and verify statistics.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Properties of the Gaussian distribution<br />
- Central Limit Theorem (preview)</p>
<p><strong>3. Real‑World Relevance</strong><br />
- Measurement error modeling<br />
- Standardized test scores / z‑scores</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                    <span class="c1"># optional</span>
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a><span class="n">normals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>     <span class="c1"># mean=0, std=1</span>
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>
<a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean:&quot;</span><span class="p">,</span> <span class="n">normals</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance:&quot;</span><span class="p">,</span> <span class="n">normals</span><span class="o">.</span><span class="n">var</span><span class="p">())</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- Mean ≈ 0, Variance ≈ 1 (allow small deviation)</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Use <code>np.random.normal(loc, scale, size)</code> for non‑standard normals<br />
- Make a QQ plot vs. theoretical normal to check normality</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- <code>plt.hist(normals, density=True)</code> to visualize the bell curve</p>
</details>
<details class="example" open="open">
<summary>Exercise 6: Sampling Distribution of the Mean</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Run 1,000 “mini‑experiments.” Each experiment rolls a die 100 times, records the mean, and we plot the distribution of those means.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Law of Large Numbers<br />
- Sampling variability decreases as sample size increases<br />
- Sampling distribution &amp; standard error</p>
<p><strong>3. Real‑World Relevance</strong><br />
- <strong>Polling averages:</strong> many small samples → distribution of means<br />
- <strong>Quality control:</strong> batch averages instead of single measurements</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># optional</span>
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)]</span>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sampling Distribution of Die Roll Means&#39;</span><span class="p">)</span>
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sample Mean&#39;</span><span class="p">)</span>
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- Histogram looks roughly normal, centered near 3.5<br />
- Spread is much narrower than individual die outcomes</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Change experiment size: n=10 vs. n=1000 → compare spreads<br />
- Compute <strong>standard error</strong>: σ / √n (use σ ≈ 1.71 for a die)</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- List comprehensions are fine here; for speed, you can vectorize with NumPy</p>
</details>
<details class="example" open="open">
<summary>Exercise 7: Weighted Dice Simulation</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Simulate 1,000 rolls of a <strong>biased</strong> die where P(6) = 0.5 and the other faces share the remaining probability.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Custom discrete distributions<br />
- How bias shifts mean and variance</p>
<p><strong>3. Real‑World Relevance</strong><br />
- Biased processes in manufacturing (defect more likely on one line)<br />
- Skewed customer behavior (one product far more popular)</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># optional</span>
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a><span class="n">faces</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a><span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">]</span><span class="o">*</span><span class="mi">5</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]</span>     <span class="c1"># 0.1 each for 1–5, 0.5 for 6</span>
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a><span class="n">rolls_biased</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">faces</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean:&quot;</span><span class="p">,</span> <span class="n">rolls_biased</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="s2">&quot;Variance:&quot;</span><span class="p">,</span> <span class="n">rolls_biased</span><span class="o">.</span><span class="n">var</span><span class="p">())</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- Mean <strong>&gt; 3.5</strong> due to heavy weight on 6<br />
- Variance will differ from the fair‑die case</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Tweak <code>probs</code> for different biases<br />
- Plot histograms for fair vs. biased dice side‑by‑side</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- Ensure <code>sum(probs) == 1</code> or NumPy will error<br />
- You can simulate many biased scenarios to stress‑test models</p>
</details>
<details class="example" open="open">
<summary>Exercise 8: Vector Addition &amp; Scaling</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Demonstrate vector addition and scalar multiplication using simple feature vectors.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Vector space operations (add, scale)<br />
- Geometric interpretation (direction &amp; length)</p>
<p><strong>3. Real‑World Relevance</strong><br />
- Combine feature effects (e.g., marketing channels)<br />
- Scale normalized data or weights</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a><span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a><span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a><span class="n">sum_v</span>   <span class="o">=</span> <span class="n">v1</span> <span class="o">+</span> <span class="n">v2</span>        <span class="c1"># vector addition</span>
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a><span class="n">scaled_v</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">v1</span>      <span class="c1"># scalar multiplication</span>
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a>
<a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sum:   &quot;</span><span class="p">,</span> <span class="n">sum_v</span><span class="p">)</span>
<a id="__codelineno-26-10" name="__codelineno-26-10" href="#__codelineno-26-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scaled:&quot;</span><span class="p">,</span> <span class="n">scaled_v</span><span class="p">)</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- <code>Sum</code> = <code>[3, 7, 11]</code><br />
- <code>Scaled</code> = <code>[1, 2, 3]</code></p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Compute the <strong>dot product</strong>: <code>v1.dot(v2)</code><br />
- Visualize 2D/3D vectors (e.g., with matplotlib quiver)</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- Ensure vectors have the same length for element‑wise ops<br />
- Scalar multiplication stretches/shrinks the vector length</p>
</details>
<details class="example" open="open">
<summary>Exercise 9: Matrix Multiplication Demonstration</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Multiply a 2×3 matrix by a 3×2 matrix to reinforce matrix‑multiplication rules and shape compatibility.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Shape rules (inner dimensions must match)<br />
- Summation over the inner index (k)</p>
<p><strong>3. Real‑World Relevance</strong><br />
- Transforming feature spaces<br />
- Chaining layers in neural networks (each layer = a matrix multiply)</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>              <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>          <span class="c1"># shape (2, 3)</span>
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a><span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
<a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>              <span class="p">[</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
<a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>              <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>          <span class="c1"># shape (3, 2)</span>
<a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>
<a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a><span class="n">C</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>            <span class="c1"># or: C = A @ B in Python 3.5+</span>
<a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>[[ 58  64]
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a> [139 154]]
</code></pre></div>
- You can verify: first row × first column → 1<em>7 + 2</em>9 + 3*11 = 58</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Try <code>B @ A</code> to see the shape error<br />
- Use larger random matrices to test performance</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- Check shapes with <code>A.shape</code>, <code>B.shape</code><br />
- <code>@</code> is shorthand for matrix multiply (<code>dot</code>) in NumPy/Python 3.5+</p>
</details>
<details class="example" open="open">
<summary>Exercise 10: PCA on Toy Dataset</summary>
<p><strong>1. Overview &amp; Purpose</strong><br />
Perform PCA on a tiny 2‑D dataset, reduce it to 1‑D, and see how much variance is captured.</p>
<p><strong>2. Concept Reinforcement</strong><br />
- Eigenvectors / eigenvalues<br />
- Dimensionality reduction &amp; variance explained</p>
<p><strong>3. Real‑World Relevance</strong><br />
- Compressing image or sensor data<br />
- Feature extraction before clustering or modeling</p>
<p><strong>4. Step-by-Step Instructions</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>
<a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
<a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>    <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">],</span>
<a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a>    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a>    <span class="p">[</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.9</span><span class="p">],</span>
<a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a>    <span class="p">[</span><span class="mf">1.9</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">],</span>
<a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>    <span class="p">[</span><span class="mf">3.1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]</span>
<a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a><span class="p">])</span>
<a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a>
<a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-29-13" name="__codelineno-29-13" href="#__codelineno-29-13"></a><span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<a id="__codelineno-29-14" name="__codelineno-29-14" href="#__codelineno-29-14"></a>
<a id="__codelineno-29-15" name="__codelineno-29-15" href="#__codelineno-29-15"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explained variance ratio:&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<a id="__codelineno-29-16" name="__codelineno-29-16" href="#__codelineno-29-16"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Projected data:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">X_pca</span><span class="p">)</span>
</code></pre></div></p>
<p><strong>5. Expected Outcomes &amp; Interpretation</strong><br />
- First component should capture ~98% of variance for this toy set<br />
- Projected 1‑D data preserves most “information” (spread)</p>
<p><strong>6. Extensions &amp; Variations</strong><br />
- Plot original 2‑D vs. projected 1‑D points<br />
- Try <code>n_components=2</code> (no reduction) and inspect components</p>
<p><strong>7. Additional Notes &amp; Tips</strong><br />
- Requires <code>scikit-learn</code> (<code>pip install scikit-learn</code> if missing)<br />
- PCA assumes linear structure; nonlinear data may need t‑SNE/UMAP</p>
</details>
<h2 id="6-week-1-summary-what-you-can-now-do">6. Week 1 Summary &amp; What You Can Now Do</h2>
<div class="admonition success">
<p class="admonition-title">You can now…</p>
<ul>
<li><strong>Explain key AI milestones</strong>: Dartmouth (1956), Expert Systems (1970s–80s), Deep Learning boom (2010s–present) and why each wave mattered.  </li>
<li><strong>Use probability concepts</strong> (random variables, mean, variance) and verify them empirically in Python.  </li>
<li><strong>Work with basic linear algebra objects</strong> (vectors, matrices, dot products, matrix multiplication) and see how they power ML models.  </li>
<li><strong>Install and run core tools</strong> (Anaconda, Jupyter, NumPy, pandas) to explore data and math interactively.</li>
</ul>
</div>
<h3 id="a-ai-history-in-one-breath">A. AI History in One Breath</h3>
<ul>
<li><strong>Dartmouth Workshop (1956):</strong> coined “AI”; optimism about simulating intelligence.<br />
<em>Lesson:</em> Ambition vs. realism—avoid hype traps.  </li>
<li><strong>Expert Systems (’70s–’80s):</strong> rule-based IF–THEN logic (e.g., MYCIN).<br />
<em>Lesson:</em> Transparency is great, but brittle without probabilities.  </li>
<li><strong>Deep Learning (2010s–):</strong> data + GPUs + better algorithms (AlexNet etc.) → breakthroughs.<br />
<em>Lesson:</em> Modern toolkits (TensorFlow/PyTorch) center on neural nets.</li>
</ul>
<h3 id="b-probability-from-intuition-to-math">B. Probability: From Intuition to Math</h3>
<ul>
<li><strong>Random Variables:</strong> discrete (die, coin), continuous (time-to-failure).  </li>
<li><strong>Expectation &amp; Variance:</strong> long-run average and spread—computed by hand and via NumPy.  </li>
<li><strong>Why it matters:</strong> Loss functions, risk estimation, feature engineering all use these ideas.  </li>
<li><strong>Real world ties:</strong> A/B tests, forecasting demand spikes, Monte Carlo risk simulations.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Anchor formulas</p>
<ul>
<li>Discrete mean: \(E[X] = \sum x_i P(X=x_i)\)  </li>
<li>Variance: \(\mathrm{Var}(X) = E[(X - E[X])^2]\)</li>
</ul>
</div>
<h3 id="c-linear-algebra-the-language-of-ml">C. Linear Algebra: The Language of ML</h3>
<ul>
<li><strong>Vectors:</strong> feature lists (e.g., <code>[age, spend, orders]</code>).  </li>
<li><strong>Matrices:</strong> batches of vectors; all your data at once.  </li>
<li><strong>Dot Product:</strong> core of regression and neuron activations.  </li>
<li><strong>Matrix Multiplication:</strong> chaining transformations (layers) in neural nets.  </li>
<li><strong>Why it matters:</strong> Speed (GPU vectorization), interpretability (weights are matrices), compression (PCA).</li>
</ul>
<h3 id="d-tools-workflow-locked-in">D. Tools &amp; Workflow Locked In</h3>
<ul>
<li><strong>Anaconda &amp; Jupyter:</strong> you spun up a notebook and ran code.  </li>
<li><strong>NumPy/pandas:</strong> you handled arrays, stats, and basic data manipulation.  </li>
<li><strong>Workflow habits:</strong> preview locally (<code>mkdocs serve</code>), commit/push, deploy (<code>gh-deploy</code>).</li>
</ul>
<h3 id="e-exercises-recap-what-each-taught-you">E. Exercises Recap (What each taught you)</h3>
<table>
<thead>
<tr>
<th>Exercise</th>
<th>Core Idea</th>
<th>Concept Reinforced</th>
<th>Real‑World Parallel</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Die roll stats</td>
<td>Empirical vs. theoretical</td>
<td>Mean, variance, sampling noise</td>
<td>QC sampling, Monte Carlo</td>
</tr>
<tr>
<td>2. Coin flips</td>
<td>Bernoulli trials</td>
<td>Discrete RVs, proportions</td>
<td>A/B tests, pass/fail outcomes</td>
</tr>
<tr>
<td>3. Histogram</td>
<td>Visual distributions</td>
<td>Frequency vs. prob., plotting</td>
<td>Category sales distributions</td>
</tr>
<tr>
<td>4. Exponential sim</td>
<td>Time-to-event model</td>
<td>Continuous RVs, λ &amp; scale</td>
<td>Failure rates, wait times</td>
</tr>
<tr>
<td>5. Normal samples</td>
<td>Gaussian basics</td>
<td>CLT preview, z-scores</td>
<td>Measurement error, scores</td>
</tr>
<tr>
<td>6. Sampling means</td>
<td>Distribution of means</td>
<td>Law of Large Numbers</td>
<td>Polling averages, batch metrics</td>
</tr>
<tr>
<td>7. Weighted die</td>
<td>Biased distributions</td>
<td>Shifted mean/var, custom PMFs</td>
<td>Skewed demand, unfair odds</td>
</tr>
<tr>
<td>8. Vector ops</td>
<td>Add/scale vectors</td>
<td>Vector spaces</td>
<td>Feature scaling, weight tuning</td>
</tr>
<tr>
<td>9. Matrix multiply</td>
<td>Shapes &amp; transforms</td>
<td>Linear maps, dot sums</td>
<td>NN layers, feature transforms</td>
</tr>
<tr>
<td>10. PCA toy data</td>
<td>Dimensionality reduction</td>
<td>Eigenvectors/variance explained</td>
<td>Data compression, preprocessing</td>
</tr>
</tbody>
</table>
<h2 id="7-additional-resources">7. Additional Resources</h2>
<div class="admonition tip">
<p class="admonition-title">Probability &amp; Statistics</p>
</div>
<ul>
<li><strong>Khan Academy – Introduction to Probability</strong><br />
  Beginner‑friendly videos and practice problems.<br />
<a href="https://www.khanacademy.org/math/statistics-probability/probability-library">https://www.khanacademy.org/math/statistics-probability/probability-library</a></li>
<li><strong>Seeing Theory (Brown University)</strong><br />
  Interactive visual explanations of probability concepts.<br />
<a href="https://seeing-theory.brown.edu/">https://seeing-theory.brown.edu/</a></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Linear Algebra</p>
</div>
<ul>
<li><strong>3Blue1Brown – <em>Essence of Linear Algebra</em></strong> (YouTube series)<br />
  Beautiful visuals for vectors, matrices, dot products, eigenvectors.<br />
<a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr</a></li>
<li><strong>Khan Academy – Linear Algebra</strong><br />
  Step‑by‑step lessons with exercises.<br />
<a href="https://www.khanacademy.org/math/linear-algebra">https://www.khanacademy.org/math/linear-algebra</a></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Python, NumPy &amp; pandas</p>
</div>
<ul>
<li><strong>Official Python Docs</strong> – Syntax, stdlib, tutorials.<br />
<a href="https://docs.python.org/3/">https://docs.python.org/3/</a></li>
<li><strong>NumPy User Guide</strong> – Arrays, broadcasting, linear algebra.<br />
<a href="https://numpy.org/doc/stable/user/">https://numpy.org/doc/stable/user/</a></li>
<li><strong>pandas Getting Started</strong> – DataFrames, cleaning, transforms.<br />
<a href="https://pandas.pydata.org/docs/getting_started/index.html">https://pandas.pydata.org/docs/getting_started/index.html</a></li>
</ul>
<div class="admonition note">
<p class="admonition-title">AI History &amp; Overviews</p>
</div>
<ul>
<li><strong>“Competing in the Age of AI” (Iansiti &amp; Lakhani) – Ch. 1–3</strong> <em>(already on your list)</em>  </li>
<li><strong>“Deep Learning” (Goodfellow, Bengio, Courville) – Intro &amp; Ch. 6–7</strong> (free online)<br />
<a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a></li>
</ul>
<div class="admonition info">
<p class="admonition-title">Visualization &amp; Math Intuition</p>
</div>
<ul>
<li><strong>Matplotlib Gallery</strong> – Quick plot recipes.<br />
<a href="https://matplotlib.org/stable/gallery/index.html">https://matplotlib.org/stable/gallery/index.html</a></li>
<li><strong>Desmos Graphing Calculator</strong> – Fast function plots and geometry.<br />
<a href="https://www.desmos.com/calculator">https://www.desmos.com/calculator</a></li>
</ul>
<div class="admonition success">
<p class="admonition-title">Bonus Cheat Sheets</p>
</div>
<ul>
<li><strong>Markdown Syntax Cheat Sheet</strong> (for editing your site)<br />
<a href="https://www.markdownguide.org/cheat-sheet/">https://www.markdownguide.org/cheat-sheet/</a></li>
<li><strong>NumPy/Pandas one‑pagers</strong> (various printable PDFs)<br />
<a href="https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf">https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf</a><br />
<a href="https://www.dataquest.io/blog/numpy-cheat-sheet/">https://www.dataquest.io/blog/numpy-cheat-sheet/</a></li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "navigation.indexes", "content.code.copy", "navigation.instant", "navigation.top", "toc.integrate"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.56ea9cef.min.js"></script>
      
    
  </body>
</html>